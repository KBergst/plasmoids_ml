{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proper-paradise",
   "metadata": {},
   "source": [
    "## Simple model using just Bx, By, Bz\n",
    " classifications: separatrices, o_structures, null\n",
    " \n",
    " variable length timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "soviet-judges",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-56f0b2d3c8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# get functions from other notebooks\n",
    "%run /tigress/kendrab/analysis-notebooks/loss_fns.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/metrics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-jordan",
   "metadata": {},
   "source": [
    "### Assemble a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"alpha\"\n",
    "# hyperparameters\n",
    "filters = 32\n",
    "kernel_size = 10\n",
    "mask_value = int(-10.0)\n",
    "epochs = 2\n",
    "# max_seq_len = 10000\n",
    "\n",
    "# input\n",
    "bx_input = keras.Input(shape=(None, 1), name=\"bx\") \n",
    "by_input = keras.Input(shape=(None, 1), name=\"by\") \n",
    "bz_input = keras.Input(shape=(None, 1), name=\"bz\") \n",
    "\n",
    "# mask any necessary values\n",
    "mask_layer = keras.layers.Masking(mask_value=mask_value)\n",
    "bx_masked = mask_layer(bx_input)\n",
    "by_masked = mask_layer(by_input)\n",
    "bz_masked = mask_layer(bz_input)\n",
    "\n",
    "# convolvesqueue\n",
    "bx_conv = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(bx_masked)\n",
    "by_conv = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(by_masked)\n",
    "bz_conv = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(bz_masked)\n",
    "# merge the layers together and convolve\n",
    "b = keras.layers.Average()([bx_conv, by_conv, bz_conv])\n",
    "b_conv = keras.layers.Conv1D(filters=filters,\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding='same')(b)\n",
    "logits = tf.keras.layers.LSTM(4, return_sequences=True)(b_conv)\n",
    "probs = tf.keras.layers.Softmax()(logits)\n",
    "# throw together the model\n",
    "model = keras.Model(\n",
    "    inputs=[bx_input, by_input, bz_input],\n",
    "    outputs=[probs])\n",
    "\n",
    "# show the model\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, \"/scratch/gpfs/kendrab/model_outs/model_\"+model_name+\".png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-apollo",
   "metadata": {},
   "source": [
    "### Get 1d sampling (If training/testing only, not building!)\n",
    "Generated by [1d_sampling](./1d_sampling.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use command line args or someting easier than throwing it here\n",
    "readpaths = ['/tigress/kendrab/03082021/'+\"1000samples_idx31_bxbybzjyvz.hdf5\",\n",
    "            '/tigress/kendrab/03082021/'+\"1000samples_idx22_bxbybzjyvz.hdf5\",\n",
    "            '/tigress/kendrab/03082021/'+\"1000samples_idx15_bxbybzjyvz.hdf5\"]\n",
    "bx_list = []\n",
    "by_list = []\n",
    "bz_list = []\n",
    "topo_list = []\n",
    "\n",
    "for filepath in readpaths:\n",
    "    file = h5py.File(filepath, 'r')\n",
    "    bx_list += list(file['bx_smooth'][:])\n",
    "    by_list += list(file['by'][:])\n",
    "    bz_list += list(file['bz_smooth'][:])\n",
    "    topo_list_tmp = list(file['topo'][:])\n",
    "    print(topo_list_tmp[0])\n",
    "    for i in range(len(topo_list_tmp)):  # I tried to vectorize this but I didn't get it to work\n",
    "        topo_list_tmp[i] = keras.utils.to_categorical(topo_list_tmp[i], num_classes=4)\n",
    "    topo_list += topo_list_tmp\n",
    "    print(topo_list_tmp[0])\n",
    "    print(topo_list[0])\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-benefit",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding='post'\n",
    "# pad and mask the samples to make everything in the batch the same size\n",
    "# masking will make the model ignore the values that aren't real\n",
    "bx_padded = keras.preprocessing.sequence.pad_sequences(bx_list, padding=padding,\n",
    "                                                       value=mask_value, dtype='float32').reshape(len(bx_list),-1,1)\n",
    "by_padded = keras.preprocessing.sequence.pad_sequences(by_list, padding=padding,\n",
    "                                                       value=mask_value, dtype='float32').reshape(len(by_list),-1,1)\n",
    "bz_padded = keras.preprocessing.sequence.pad_sequences(bz_list, padding=padding,\n",
    "                                                       value=mask_value, dtype='float32').reshape(len(bz_list),-1,1)\n",
    "topo_padded = keras.preprocessing.sequence.pad_sequences(topo_list, padding=padding, value=mask_value,\n",
    "                                                        dtype='float32')\n",
    "\n",
    "print(bx_padded.shape)\n",
    "(bx_train, bx_test, by_train, by_test, bz_train, bz_test, topo_train, topo_test) = \\\n",
    "                       train_test_split(bx_padded, by_padded, bz_padded, topo_padded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-picking",
   "metadata": {},
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = tfa.losses.SigmoidFocalCrossEntropy(gamma=10)  # gamma must be an integer apparently (in int form)\n",
    "loss = gen_loss_per_pt(mask_layer=mask_layer, loss_fn=loss_fn)\n",
    "metric = gen_metric_per_cat(mask_layer=mask_layer)\n",
    "metrics = [\"acc\"]  # loss_fn keyword left default\n",
    "# for i in range(4):\n",
    "#     metrics.append(gen_metric_per_cat(mask_layer=mask_layer, cat_idx=i))\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=metrics,\n",
    "             run_eagerly = True)  # run eagerly to get .numpy() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x={'bx': bx_train, 'by': by_train, 'bz': bz_train}, y = topo_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-optics",
   "metadata": {},
   "source": [
    "### Observe the results, debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([np.max(topo_train[:,:,i]) for i in range(4)])\n",
    "print([np.max(model(inputs={'bx': bx_train, 'by': by_train, 'bz': bz_train})[:,:,i]) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
