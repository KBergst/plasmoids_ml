{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinct-trustee",
   "metadata": {},
   "source": [
    "### Preprocessing utilities\n",
    "\n",
    "Anything I might possibly reuse in preprocessing that is easily separated will be put here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_subsects(ragged_batch, window, stride, axis=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Takes a list of timeseries samples with differing lengths and creates a new batch if timeseries\n",
    "    of the same length by taking sliding windows of each timeseries in the batch.\n",
    "    If the batch isn't ragged, there is undoubtedly a more efficient way to do this \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ragged_batch : list of array-likes\n",
    "        list of timeseries samples with differing lengths. Must be of shape (tseries_i_len, *tseries_shape)\n",
    "        where tseries_i_len can be unique to each timeseries in the batch but \n",
    "    window : int\n",
    "        size of window desired\n",
    "    stride : int\n",
    "        length of stride to take between window starting points (sections overlap if stride < window)\n",
    "    axis : int, default 0\n",
    "        axis which will be the new batch size\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_batch : numpy array\n",
    "        the new batch of timeseries samples. Default shape (new_batch_len, window, *ragged_batch[0].shape[1:])\n",
    "    \"\"\"\n",
    "    \n",
    "    new_batch_list = []\n",
    "    \n",
    "    for series in ragged_batch:\n",
    "        slen = series.shape[0]\n",
    "        if slen < window:  # can't use if segment is too smol\n",
    "            continue\n",
    "        idxs = np.array([i for i in range(slen)])\n",
    "        starting_idxs = idxs[:slen-window:stride]\n",
    "        new_batch_list += [series[starting_idxs[i]:starting_idxs[i]+window] for i in range(len(starting_idxs))]\n",
    "        \n",
    "    new_batch = np.stack(new_batch_list, axis=axis) # shove it all together\n",
    "    \n",
    "    return new_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_ctrl_group(inputs_list, labels, null_label=0, thinning_factor=.5, seed=27):\n",
    "    \"\"\"\n",
    "    Removes some of the control group of a categorical / series by-datapoint categorical dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs_list : list of arrays of shape (batch_size, ~, samples_length)\n",
    "        The input to thin (may contain multiple datasets)\n",
    "    labels : array of shape (batch_size, samples_length)\n",
    "        The labels for the input dataset. Categories could be one-hot or otherwise\n",
    "        so long as the null label matches the kwarg passed in (default 0)\n",
    "    null_label : value or numpy array of values\n",
    "        the label for the overrepresented (control group) category\n",
    "    thinning_factor : float\n",
    "        The factor to reduce. balanced_batch_size = batch_size - int(ctrlgrp_batch_size * thinning_factor)\n",
    "        Can't be greater than 1 or less than 0.\n",
    "    seed : int\n",
    "        Seed for the random selection of nonevents to delete\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    balanced_inputs_list : list of arrays of shape (balanced_batch_size,~, samples_length)\n",
    "        Inputs with less null category overrepresentation\n",
    "    balanced_labels : array of shape (balanced_batch_size, categorization, samples_length)\n",
    "        Labels with less null category overrepresentation\n",
    "    \n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2021)  # better than doing np.random.seed() because that is a global change\n",
    "    if type(inputs_list) is not list:\n",
    "        raise ValueError(\"Please format your inputs as a list, even if you have only one input.\")\n",
    "    if not hasattr(null_label, \"__len__\"):  # single value to vector for comparing\n",
    "        null_label = np.array([null_label])\n",
    "    null_label_compat = np.expand_dims(null_label, (0)) # reshape label array to broadcast for comparison w/ labels\n",
    "    print(null_label_compat)\n",
    "    print(labels.shape)\n",
    "    print(f\"Total batch: {labels.shape[0]}\")\n",
    "    balanced_inputs_list = []\n",
    "    non_batch_axes = tuple( i for i in range(1,len(labels.shape)))\n",
    "    non_null_units = labels != null_label_compat  # null_label_compat gets broadcast from (1,1,categorization)?\n",
    "    non_null_samples = np.sum(non_null_units, axis=non_batch_axes)  # should be 1d now. Values positive integers or 0\n",
    "    null_samples = np.nonzero(non_null_samples == 0)[0] # now we know where we need to thin\n",
    "    # !!! remember np.nonzero returns tuple of tuples !!!\n",
    "    num_null_samples = len(null_samples)\n",
    "    print(f\"Number of null samples: {num_null_samples}\")\n",
    "    print(f\"Number of non-null samples: {np.sum(non_null_samples != 0)}\")\n",
    "    \n",
    "    # pick null samples to delete via rng\n",
    "    num_dels = int(thinning_factor*num_null_samples)\n",
    "    print(f\"With thinning factor {thinning_factor} will remove {num_dels} null samples\")\n",
    "    rdels = tuple(rng.choice(null_samples, num_dels, replace=False)) # which batch rows to delete\n",
    "    \n",
    "    for inputs in inputs_list:\n",
    "        balanced_inputs_list.append(np.delete(inputs, rdels, axis=0))\n",
    "    balanced_labels = np.delete(labels, rdels, axis=0)    \n",
    "    \n",
    "    return balanced_inputs_list, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rebalance_ctrl_group_tf(inputs_list, labels, null_label=0, thinning_factor=.5, seed=27):\n",
    "#     \"\"\"\n",
    "#     USES TENSORFLOW CONVENTION SHAPE\n",
    "#     Removes some of the control group of a categorical / series by-datapoint categorical dataset\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     inputs_list : list of arrays of shape (batch_size, samples_length, ~)\n",
    "#         The input to thin (may contain multiple datasets)\n",
    "#     labels : array of shape (batch_size, categorization)\n",
    "#         The labels for the input dataset. Categories could be one-hot or otherwise\n",
    "#         so long as the null label matches the kwarg passed in (default 0)\n",
    "#     null_label : value or numpy array of values\n",
    "#         the label for the overrepresented (control group) category\n",
    "#     thinning_factor : float\n",
    "#         The factor to reduce. balanced_batch_size = batch_size - int(ctrlgrp_batch_size * thinning_factor)\n",
    "#         Can't be greater than 1 or less than 0.\n",
    "#     seed : int\n",
    "#         Seed for the random selection of nonevents to delete\n",
    "    \n",
    "#     Outputs\n",
    "#     -------\n",
    "#     balanced_inputs_list : list of arrays of shape (balanced_batch_size, samples_length, ~)\n",
    "#         Inputs with less null category overrepresentation\n",
    "#     balanced_labels : array of shape (balanced_batch_size, samples_length, categorization)\n",
    "#         Labels with less null category overrepresentation\n",
    "    \n",
    "#     \"\"\"\n",
    "#     rng = np.random.default_rng(2021)  # better than doing np.random.seed() because that is a global change\n",
    "#     if type(inputs_list) is not list:\n",
    "#         raise ValueError(\"Please format your inputs as a list, even if you have only one input.\")\n",
    "#     if not hasattr(null_label, \"__len__\"):  # single value to vector for comparing\n",
    "#         null_label = np.array([null_label])\n",
    "#     null_label_compat = np.reshape(null_label, (1, 1, *labels.shape[2:])) # reshape label array to broadcast for comparison w/ labels\n",
    "#     print(f\"Total batch: {labels.shape[0]}\")\n",
    "#     balanced_inputs_list = []\n",
    "#     non_batch_axes = tuple( i for i in range(1,len(labels.shape)))\n",
    "#     non_null_units = labels != null_label_compat  # null_label_compat gets broadcast from (1,1,categorization)?\n",
    "#     non_null_samples = np.sum(non_null_units, axis=non_batch_axes)  # should be 1d now. Values positive integers or 0\n",
    "#     null_samples = np.nonzero(non_null_samples == 0)[0] # now we know where we need to thin\n",
    "#     # !!! remember np.nonzero returns tuple of tuples !!!\n",
    "#     num_null_samples = len(null_samples)\n",
    "#     print(f\"Number of null samples: {num_null_samples}\")\n",
    "#     print(f\"Number of non-null samples: {np.sum(non_null_samples != 0)}\")\n",
    "    \n",
    "#     # pick null samples to delete via rng\n",
    "#     num_dels = int(thinning_factor*num_null_samples)\n",
    "#     print(f\"With thinning factor {thinning_factor} will remove {num_dels} null samples\")\n",
    "#     rdels = tuple(rng.choice(null_samples, num_dels, replace=False)) # which batch rows to delete\n",
    "    \n",
    "#     for inputs in inputs_list:\n",
    "#         balanced_inputs_list.append(np.delete(inputs, rdels, axis=0))\n",
    "#     balanced_labels = np.delete(labels, rdels, axis=0)    \n",
    "    \n",
    "#     return balanced_inputs_list, balanced_labels\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_unpadded_subsects(ragged_batch, padding, stride, axis=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Takes a list of timeseries samples with differing lengths and creates a new batch of timeseries. \n",
    "    Intended for TRUE VALUES used in the loss function evaluation when the INPUT VALUES are taking additional (padding)\n",
    "    datapoints outside of the prediction timewindow. That way each padded input segment matches correctly to a non-padded 'true value'\n",
    "    segment.\n",
    "    If the batch isn't ragged, there is undoubtedly a more efficient way to do this. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ragged_batch : list of array-likes\n",
    "        list of timeseries samples with differing lengths. Must be of shape (tseries_i_len, *tseries_shape)\n",
    "        where tseries_i_len can be unique to each timeseries in the batch but \n",
    "    padding : int\n",
    "        amount of datapoints to omit on each side of each array to account for padding on other inputs\n",
    "    stride : int\n",
    "        length of stride to take between window starting points (sections overlap if stride < window)\n",
    "    axis : int, default 0\n",
    "        axis which will be the new batch size\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_batch : numpy array\n",
    "        the new batch of timeseries samples. Default shape (new_batch_len, window, *ragged_batch[0].shape[1:])\n",
    "    \"\"\"\n",
    "    new_batch_list = []\n",
    "    \n",
    "    for series in ragged_batch:\n",
    "        slen = series.shape[0]\n",
    "        idxs = np.array([i for i in range(slen)])\n",
    "        starting_idxs = idxs[padding:slen-stride-padding:stride]\n",
    "        new_batch_list += [series[starting_idxs[i]:starting_idxs[i]+stride] for i in range(len(starting_idxs))]\n",
    "        \n",
    "    new_batch = np.stack(new_batch_list, axis=axis) # shove it all together\n",
    "    \n",
    "    return new_batch\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
