{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be22a39a-18e0-43eb-bbcf-d8766cd798c3",
   "metadata": {},
   "source": [
    "used with [domain_adaptation_1](./domain_adaptation_1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e50a95e-a529-40b2-a58c-c2a4beb0b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "import numpy as np\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896e1df-6fdb-4378-a52c-7b62928f5175",
   "metadata": {},
   "source": [
    "## Feature extractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79d27fc7-9a3d-429e-8d98-ad5851d9fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters (fixed)\n",
    "padding_length = 39  # amount of data on each side of each segment for additional info\n",
    "stride = 11  # size (and therefore spacing) of each segment\n",
    "input_length = stride + 2*padding_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2bbce44c-df2a-49b4-b45a-7056197cd909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_layers_n_times(layer_list, n):  # this instead of something simpler to be absolutely sure the layers are different objects and not repeating the same one\n",
    "    new_layer_list = []\n",
    "    for i in range(n):\n",
    "        for layer in layer_list:\n",
    "            new_layer_list.append(copy.deepcopy(layer))\n",
    "    return new_layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0472fed5-a93e-4a50-bef6-9e56073a0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMSFeatExtract(nn.Module): #TODO: strided convolution instead of pooling?\n",
    "    \"\"\" 1D CNN Model \"\"\"\n",
    "    def __init__(self, mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate, mms_dropout_fraction, feat_shape):\n",
    "        super().__init__()\n",
    "        # define these all separately because they will get different weights\n",
    "        # consider smooshing these together into one convolution with in_channels=6. Idk if a good idea\n",
    "        feat_shape_nobatch = feat_shape[1:]\n",
    "        self.bx_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.by_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.bz_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.ex_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.ey_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.ez_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.jy_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        \n",
    "        self.post_merge_layers = nn.Sequential(nn.Conv1d(mms_out_channels, mms_out_channels*2, mms_kernel_size,\n",
    "                                                         padding='valid'),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.AvgPool1d(mms_pool_size))\n",
    "        self.resize_features = nn.Sequential(nn.Flatten(), nn.LazyLinear(np.prod(feat_shape_nobatch)), nn.Unflatten(-1, feat_shape_nobatch))\n",
    "                                               \n",
    "\n",
    "    def forward(self, bx, by, bz, ex, ey, ez, jy):\n",
    "        bx_proc = self.bx_layers(bx)\n",
    "        by_proc = self.by_layers(by)\n",
    "        bz_proc = self.bz_layers(bz)\n",
    "        ex_proc = self.ex_layers(ex)\n",
    "        ey_proc = self.ey_layers(ey)\n",
    "        ez_proc = self.ez_layers(ez)\n",
    "        jy_proc = self.jy_layers(jy)\n",
    "        combined = (bx_proc + by_proc + bz_proc + ex_proc + ey_proc + ez_proc + jy_proc)/6.\n",
    "        mms_features = self.post_merge_layers(combined)\n",
    "        features = self.resize_features(mms_features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d88ea-af6c-47da-a527-1de0817aa123",
   "metadata": {},
   "source": [
    "## Discriminator part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66709e99-5f96-4517-bd3c-b988dcd61bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):  # TODO: use leaky ReLU instead? advised for dcgan\n",
    "    \"\"\" Based on the Tzeng et al. model \"\"\"\n",
    "    def __init__(self, discrim_width, discrim_length):\n",
    "        super().__init__()        \n",
    "        self.layers = nn.Sequential(*repeat_layers_n_times([nn.LazyLinear(discrim_width), nn.LeakyReLU()], discrim_length))\n",
    "        self.domain_label = nn.Sequential(nn.Linear(discrim_width, 1))\n",
    "        \n",
    "    def forward(self,features):\n",
    "        batch_size = features.shape[0]\n",
    "        layers_out = self.layers(features.view(batch_size,-1))\n",
    "        domain_pred_logit = self.domain_label(layers_out).view(-1)\n",
    "        \n",
    "        return domain_pred_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03206a0a-35e1-44c8-b379-f4d3765a4528",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de6592fe-d43f-4ae6-acd0-7b6515111ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adda(dl_source, dl_target, feat_extract_source, feat_extract_target, discriminator,\n",
    "               loss_fn_disc, loss_fn_feat, optimizer_disc, optimizer_feat, iter_source=None):\n",
    "    # note feat_extract_source is a special boye that returns a dictionary that we need to get a value from\n",
    "    # backpropagate feat extractor (target) w/ GAN loss\n",
    "    # backpropagate discriminator w/ cross entropy loss (log? am confuse)\n",
    "    inter_iteration_stuff = {}  # whatever I need to escape this function (losses over time, the current iterator, etc.)\n",
    "    feat_extract_source.eval()\n",
    "    batch_size = dl_source.batch_size  # the length of a tensordataset is the batch size (shared first dim)\n",
    "    y_s = torch.zeros(batch_size, device=device, dtype=dtype)  # labels. target = 1, source = 0.\n",
    "    y_t = torch.ones(batch_size, device=device, dtype=dtype)\n",
    "    \n",
    "    # let's iterate enough that the mms dataset is completely used. \n",
    "    samples_source = len(dl_source.dataset)\n",
    "    samples_target = len(dl_target.dataset)\n",
    "    total_batches =samples_target//batch_size\n",
    "    print(f\"training on {samples_source} source samples and {samples_target} target samples\")\n",
    "    # iterate\n",
    "    if iter_source is None:  # make the source iterator if it doesn't already exist\n",
    "        print(\"Making source iterator\")  # shouldn't ever fire with current setup / needs from the code\n",
    "        iter_source = iter(dl_source)\n",
    "    iter_target = iter(dl_target)\n",
    "    for batch in range(total_batches):\n",
    "        ds_source, iter_source = iter_or_restart_dl(dl_source, iter_source)\n",
    "        ds_target, iter_target = iter_or_restart_dl(dl_target, iter_target)\n",
    "        loss_disc = []\n",
    "        loss_feat = []\n",
    "        # unpack values\n",
    "        _, _, bx_s, by_s, bz_s, ex_s, ey_s, ez_s, jy_s, _, _, _ = ds_source\n",
    "        bx_t, by_t, bz_t, ex_t, ey_t, ez_t, _, jy_t, _, _ = ds_target\n",
    "        # calculate features, add labels\n",
    "        feat_source = feat_extract_source(bx_s, by_s, bz_s, ex_s, ey_s, ez_s, jy_s)[\"features\"].detach()  # don't calc gradient\n",
    "        feat_target = feat_extract_target(bx_t, by_t, bz_t, ex_t, ey_t, ez_t, jy_t)\n",
    "        \n",
    "        feat_extract_target.train()\n",
    "        discriminator.train()\n",
    "        \n",
    "        # train the discriminator\n",
    "        optimizer_disc.zero_grad()\n",
    "            # on source\n",
    "        pred_source = discriminator(feat_source)\n",
    "        lossD_source = loss_fn_disc(pred_source,y_s)\n",
    "        lossD_source.backward()  # DO NOT STEP YET need to accumulate more\n",
    "            # on target\n",
    "        pred_target = discriminator(feat_target.detach())  # don't calc feat_target gradient\n",
    "        lossD_target = loss_fn_disc(pred_target, y_t)\n",
    "        lossD_target.backward()  # accumulate gradients\n",
    "        lossD = lossD_source + lossD_target\n",
    "        optimizer_disc.step()\n",
    "        \n",
    "        # train the target feature extractor\n",
    "        optimizer_feat.zero_grad()\n",
    "        pred_target = discriminator(feat_target)\n",
    "        lossF = loss_fn_feat(pred_target, y_s)  # loss with reversed labels\n",
    "        lossF.backward()\n",
    "        optimizer_feat.step() \n",
    "        loss_disc.append(lossD.item())\n",
    "        loss_feat.append(lossF.item())\n",
    "\n",
    "        if (batch+1) % 50 == 0:\n",
    "            current_sample = (batch+1)*batch_size\n",
    "            print(f\"discrim loss: {lossD}, feat extract loss: {lossF}, sample {current_sample}/{total_batches*batch_size}\")\n",
    "    # configure function outputs \n",
    "    inter_iteration_stuff[\"iter_source\"] = iter_source\n",
    "    if \"loss_disc\" not in inter_iteration_stuff:\n",
    "        inter_iteration_stuff[\"loss_disc\"] = []  # start if not already there\n",
    "    if \"loss_feat\" not in inter_iteration_stuff:\n",
    "        inter_iteration_stuff[\"loss_feat\"] = [] \n",
    "    inter_iteration_stuff[\"loss_disc\"] += loss_disc\n",
    "    inter_iteration_stuff[\"loss_feat\"] += loss_feat\n",
    "    \n",
    "    return inter_iteration_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f385bdbb-ff24-46aa-b674-4bcf841e4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the mms feature extractor with the one for the sim data. should be ok starting point\n",
    "# optimizer for target feature extractor need both it and discriminator for correct backpropagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c555b410-7db7-42cd-b957-177b0e3f8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adda(mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate, mms_dropout_fraction,\n",
    "                discrim_width, discrim_length, feat_shape):\n",
    "    discrim = Discriminator(discrim_width, discrim_length).to(device=device, dtype=torch.double)\n",
    "    feat_mms = MMSFeatExtract(mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate,\n",
    "                              mms_dropout_fraction, feat_shape).to(device=device, dtype=torch.double)\n",
    "    feat_mms.apply(weights_init)  # apply gaussian weights\n",
    "#    print(discrim)\n",
    "#    print(feat_mms)\n",
    "    return discrim, feat_mms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d8cff6-4fc4-45c6-aad6-74a51631a6f9",
   "metadata": {},
   "source": [
    "### If run alone: save a model with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3fa1d7-6829-45c4-adee-77f9ca02060a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():  # do not run if %run from another notebook\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "    dtype = torch.double\n",
    "    %run /tigress/kendrab/analysis-notebooks/torch_models/utils.ipynb\n",
    "    # some sim model hyperparameters\n",
    "    padding_length = 39  # amount of data on each side of each segment for additional info\n",
    "    stride = 11  # size (and therefore spacing) of each segment\n",
    "    input_length = stride + 2*padding_length\n",
    "    batch_size = 11\n",
    "    mms_kp_limit = 9  # not neeeded when loading from file\n",
    "    mms_num_conv = 1\n",
    "    mms_kernel_size = 3\n",
    "    mms_pool_size = 4\n",
    "    mms_out_channels = 40\n",
    "    mms_learning_rate = 0.0012094769607738786\n",
    "    mms_dropout_fraction = 0.03457536835651724\n",
    "    feat_shape = [batch_size, 72, 3]\n",
    "    mock_data = torch.ones((batch_size, 1, input_length), dtype=dtype)\n",
    "    feat_mms = MMSFeatExtract(mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate,\n",
    "                              mms_dropout_fraction, feat_shape).to(device=device, dtype=torch.double)\n",
    "    # dry run to initialize lazy modules\n",
    "    feat_mms(*[mock_data for i in range(7)])\n",
    "    print(torchinfo.summary(feat_mms))\n",
    "    feat_mms.apply(lambda m: weights_init(m, mean=-0.16, stdev=1.46))  # apply gaussian weights  \n",
    "    torch.save(feat_mms.state_dict(), \"/tigress/kendrab/analysis-notebooks/model_outs/\"+\"mms_random_featextract_statedict.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311aa89f-df6f-4f6d-b403-a2c6ed584138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
