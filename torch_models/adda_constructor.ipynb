{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be22a39a-18e0-43eb-bbcf-d8766cd798c3",
   "metadata": {},
   "source": [
    "used with [domain_adaptation_1](./domain_adaptation_1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896e1df-6fdb-4378-a52c-7b62928f5175",
   "metadata": {},
   "source": [
    "## Feature extractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d27fc7-9a3d-429e-8d98-ad5851d9fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "padding_length = 10  # amount of data on each side of each segment for additional info\n",
    "stride = 10  # size (and therefore spacing) of each segment\n",
    "input_length = stride + 2*padding_length\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "out_channels = 32  # like 'filters' in keras\n",
    "\n",
    "discrim_width = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472fed5-a93e-4a50-bef6-9e56073a0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMSFeatExtract(nn.Module): #TODO: leaky relu? strided convolution instead of pooling?\n",
    "    \"\"\" 1D CNN Model \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # define these all separately because they will get different weights\n",
    "        # consider smooshing these together into one convolution with in_channels=6. Idk if a good idea\n",
    "        self.bx_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.AvgPool1d(pool_size))\n",
    "        self.by_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.AvgPool1d(pool_size))\n",
    "        self.bz_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.AvgPool1d(pool_size))\n",
    "        self.ex_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.AvgPool1d(pool_size))\n",
    "        self.ey_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.AvgPool1d(pool_size))\n",
    "        self.ez_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.AvgPool1d(pool_size))\n",
    "        self.jy_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.AvgPool1d(pool_size))\n",
    "        \n",
    "        # TODO split this into CNN and classifier parts to facilitate domain adaptation\n",
    "        self.post_merge_layers = nn.Sequential(nn.Conv1d(out_channels, out_channels*2, kernel_size,\n",
    "                                                         padding='valid'),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.AvgPool1d(pool_size))\n",
    "                                               \n",
    "\n",
    "    def forward(self, bx, by, bz, ex, ey, ez, jy):\n",
    "        bx_proc = self.bx_layers(bx)\n",
    "        by_proc = self.by_layers(by)\n",
    "        bz_proc = self.bz_layers(bz)\n",
    "        ex_proc = self.ex_layers(ex)\n",
    "        ey_proc = self.ey_layers(ey)\n",
    "        ez_proc = self.ez_layers(ez)\n",
    "        jy_proc = self.jy_layers(jy)\n",
    "        combined = (bx_proc + by_proc + bz_proc + ex_proc + ey_proc + ez_proc + jy_proc)/6.\n",
    "        features = self.post_merge_layers(combined)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d88ea-af6c-47da-a527-1de0817aa123",
   "metadata": {},
   "source": [
    "## Discriminator part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66709e99-5f96-4517-bd3c-b988dcd61bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):  # TODO: use leaky ReLU instead? advised for dcgan\n",
    "    \"\"\" Based on the Tzeng et al. model \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.layer1 = nn.Sequential(nn.LazyLinear(discrim_width), nn.LeakyReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Linear(discrim_width, discrim_width), nn.LeakyReLU())\n",
    "        self.domain_label = nn.Sequential(nn.Linear(discrim_width, 1), nn.LeakyReLU())\n",
    "        \n",
    "    def forward(self,features):\n",
    "        batch_size = features.shape[0]\n",
    "        layer1_out = self.layer1(features.view(batch_size,-1))\n",
    "        layer2_out = self.layer2(layer1_out)\n",
    "        domain_pred_logit = self.domain_label(layer2_out).view(-1)\n",
    "        \n",
    "        return domain_pred_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03206a0a-35e1-44c8-b379-f4d3765a4528",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6592fe-d43f-4ae6-acd0-7b6515111ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adda(dl_source, dl_target, feat_extract_source, feat_extract_target, discriminator,\n",
    "               loss_fn, optimizer_disc, optimizer_feat, iter_source=None):\n",
    "    # note feat_extract_source is a special boye that returns a dictionary that we need to get a value from\n",
    "    # backpropagate feat extractor (target) w/ GAN loss\n",
    "    # backpropagate discriminator w/ cross entropy loss (log? am confuse)\n",
    "    inter_iteration_stuff = {}  # whatever I need to escape this function (losses over time, the current iterator, etc.)\n",
    "    feat_extract_source.eval()\n",
    "    batch_size = dl_source.batch_size  # the length of a tensordataset is the batch size (shared first dim)\n",
    "    y_s = torch.zeros(batch_size, device=device, dtype=dtype)  # labels. target = 1, source = 0.\n",
    "    y_t = torch.ones(batch_size, device=device, dtype=dtype)\n",
    "    \n",
    "    # let's iterate enough that the mms dataset is completely used. \n",
    "    samples_source = len(dl_source.dataset)\n",
    "    samples_target = len(dl_target.dataset)\n",
    "    total_batches =samples_target//batch_size\n",
    "    print(f\"training on {samples_source} source samples and {samples_target} target samples\")\n",
    "    # iterate\n",
    "    if iter_source is None:  # make the source iterator if it doesn't already exist\n",
    "        print(\"Making source iterator\")  # shouldn't ever fire with current setup / needs from the code\n",
    "        iter_source = iter(dl_source)\n",
    "    iter_target = iter(dl_target)\n",
    "    for batch in range(total_batches):\n",
    "        ds_source, iter_source = iter_or_restart_dl(dl_source, iter_source)\n",
    "        ds_target, iter_target = iter_or_restart_dl(dl_target, iter_target)\n",
    "        loss_disc = []\n",
    "        loss_feat = []\n",
    "        # unpack values\n",
    "        _, _, bx_s, by_s, bz_s, ex_s, ey_s, ez_s, jy_s, _, _, _ = ds_source\n",
    "        bx_t, by_t, bz_t, ex_t, ey_t, ez_t, _, jy_t, _, _ = ds_target\n",
    "        # calculate features, add labels\n",
    "        feat_source = feat_extract_source(bx_s, by_s, bz_s, ex_s, ey_s, ez_s, jy_s)[\"features\"].detach()  # don't calc gradient\n",
    "        feat_target = feat_extract_target(bx_t, by_t, bz_t, ex_t, ey_t, ez_t, jy_t)\n",
    "        \n",
    "        feat_extract_target.train()\n",
    "        discriminator.train()\n",
    "        \n",
    "        # train the discriminator\n",
    "        optimizer_disc.zero_grad()\n",
    "            # on source\n",
    "        pred_source = discriminator(feat_source)\n",
    "        lossD_source = loss_fn(pred_source,y_s)\n",
    "        lossD_source.backward()  # DO NOT STEP YET need to accumulate more\n",
    "            # on target\n",
    "        pred_target = discriminator(feat_target.detach())  # don't calc feat_target gradient\n",
    "        lossD_target = loss_fn(pred_target, y_t)\n",
    "        lossD_target.backward()  # accumulate gradients\n",
    "        lossD = lossD_source + lossD_target\n",
    "        optimizer_disc.step()\n",
    "        \n",
    "        # train the target feature extractor\n",
    "        optimizer_feat.zero_grad()\n",
    "        pred_target = discriminator(feat_target)\n",
    "        lossF = loss_fn(pred_target, y_s)  # loss with reversed labels\n",
    "        lossF.backward()\n",
    "        optimizer_feat.step() \n",
    "        loss_disc.append(lossD.item())\n",
    "        loss_feat.append(lossF.item())\n",
    "\n",
    "        if (batch+1) % 50 == 0:\n",
    "            current_sample = (batch+1)*batch_size\n",
    "            print(f\"discrim loss: {lossD}, feat extract loss: {lossF}, sample {current_sample}/{total_batches*batch_size}\")\n",
    "    # configure function outputs \n",
    "    inter_iteration_stuff[\"iter_source\"] = iter_source\n",
    "    if \"loss_disc\" not in inter_iteration_stuff:\n",
    "        inter_iteration_stuff[\"loss_disc\"] = []  # start if not already there\n",
    "    if \"loss_feat\" not in inter_iteration_stuff:\n",
    "        inter_iteration_stuff[\"loss_feat\"] = [] \n",
    "    inter_iteration_stuff[\"loss_disc\"] += loss_disc\n",
    "    inter_iteration_stuff[\"loss_feat\"] += loss_feat\n",
    "    \n",
    "    return inter_iteration_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385bdbb-ff24-46aa-b674-4bcf841e4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the mms feature extractor with the one for the sim data. should be ok starting point\n",
    "# optimizer for target feature extractor need both it and discriminator for correct backpropagation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555b410-7db7-42cd-b957-177b0e3f8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim = Discriminator().to(device=device, dtype=torch.double)\n",
    "feat_mms = MMSFeatExtract().to(device=device, dtype=torch.double)\n",
    "feat_mms.apply(weights_init)\n",
    "print(discrim)\n",
    "print(feat_mms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
