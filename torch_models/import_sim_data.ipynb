{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc3ab82-fa4d-4f12-8e3c-e4f75415551e",
   "metadata": {},
   "source": [
    "used with [domain_adaptation_1](./domain_adaptation_1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c93d15-d9e4-4da9-b6f6-32c8830d08f1",
   "metadata": {},
   "source": [
    "## get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de5b8c-85be-4e98-ae29-08e6176158ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use command line args or someting easier than throwing it here\n",
    "basedir = '/tigress/kendrab/21032023/'\n",
    "readpaths = []\n",
    "noplasmoids_dir = '/tigress/kendrab/06022023/'\n",
    "noplasmoids_paths = []\n",
    "\n",
    "for i in range(10):\n",
    "    totdir = basedir+str(i)+'/'\n",
    "    for j in range(5,60,5):\n",
    "        readpaths.append(totdir+f\"100samples_idx{j}_bxbybzjyvzexeyez.hdf5\")\n",
    "        \n",
    "for j in range(5,55,5):\n",
    "        noplasmoids_paths.append(noplasmoids_dir+f\"100samples_idx{j}_bxbybzjyvzexeyez.hdf5\")\n",
    "        \n",
    "idx_list = []  # to keep track of which file what sample came from\n",
    "s_list = []\n",
    "bx_list = []\n",
    "by_list = []\n",
    "bz_list = []\n",
    "ex_list = []\n",
    "ey_list = []\n",
    "ez_list = []\n",
    "jy_list = []\n",
    "x0_list = []\n",
    "x1_list = []\n",
    "topo_list = []\n",
    "\n",
    "train_idx = None\n",
    "# import the messy current sheet data\n",
    "for idx, filepath in enumerate(readpaths):\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        idx_list += [np.array([idx for i in bx]) for bx in file['bx_mms_smooth'][:]]  # check this structure!!!\n",
    "        s_list += list(file['s'][:])\n",
    "        bx_list += list(file['bx_mms_smooth'][:])\n",
    "        by_list += list(file['by_mms'][:])\n",
    "        bz_list += list(file['bz_mms_smooth'][:])\n",
    "        ex_list += list(file['ex_mms'][:]) \n",
    "        ey_list += list(file['ey_mms'][:])\n",
    "        ez_list += list(file['ez_mms'][:])  # vx_mms is simulation vz  thus the filename \n",
    "        jy_list += list(file['jy_mms'][:])\n",
    "        x0_list += list(file['x_mms'][:])\n",
    "        x1_list += list(file['z_mms'][:])\n",
    "        topo_list_tmp = list(file['topo'][:])\n",
    "        for i in range(len(topo_list_tmp)):  # I tried to vectorize this but I didn't get it to work\n",
    "            topo_list_tmp[i] = torch.from_numpy(topo_list_tmp[i].astype(int) % 2)  # cat 0,2 are not plasmoids, cat 1,3 are\n",
    "            topo_list_tmp[i] = one_hot(topo_list_tmp[i], num_classes=2)\n",
    "        topo_list += topo_list_tmp\n",
    "        \n",
    "# import the smooth current sheet data\n",
    "for idx, filepath in enumerate(noplasmoids_paths):\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        idx_list += [np.array([idx for i in bx]) for bx in file['bx_mms_smooth'][:]]  # check this structure!!!\n",
    "        s_list += list(file['s'][:])\n",
    "        bx_list += list(file['bx_mms_smooth'][:])\n",
    "        by_list += list(file['by_mms'][:])\n",
    "        bz_list += list(file['bz_mms_smooth'][:])\n",
    "        ex_list += list(file['ex_mms'][:]) \n",
    "        ey_list += list(file['ey_mms'][:])\n",
    "        ez_list += list(file['ez_mms'][:])  # vx_mms is simulation vz  thus the filename \n",
    "        jy_list += list(file['jy_mms'][:])\n",
    "        x0_list += list(file['x_mms'][:])\n",
    "        x1_list += list(file['z_mms'][:])\n",
    "        topo_list_tmp = list(file['topo'][:])\n",
    "        # FIX THIS\n",
    "        for i in range(len(topo_list_tmp)):  # I tried to vectorize this but I didn't get it to work\n",
    "            topo_list_tmp[i] = torch.from_numpy(topo_list_tmp[i].astype(int) % 2)  # cat 0,2 are not plasmoids, cat 1,3 are\n",
    "            topo_list_tmp[i] = one_hot(topo_list_tmp[i], num_classes=2)\n",
    "        topo_list += topo_list_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd1cd9-fa58-4891-ad0e-f544255cb2ab",
   "metadata": {},
   "source": [
    "## chunk the data and put in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332aeb4a-606e-4443-8b11-0ece8d979fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = batch_unpadded_subsects(idx_list, padding_length, stride)\n",
    "s = batch_subsects(s_list, input_length, stride)  # not going through training so don't need to shape right\n",
    "bx = np.expand_dims(batch_subsects(bx_list, input_length, stride),1)\n",
    "by = np.expand_dims(batch_subsects(by_list, input_length, stride),1)\n",
    "bz = np.expand_dims(batch_subsects(bz_list, input_length, stride),1)\n",
    "ex = np.expand_dims(batch_subsects(ex_list, input_length, stride),1)\n",
    "ey = np.expand_dims(batch_subsects(ey_list, input_length, stride),1)\n",
    "ez = np.expand_dims(batch_subsects(ez_list, input_length, stride),1)\n",
    "jy = np.expand_dims(batch_subsects(jy_list, input_length, stride),1)\n",
    "x0 = batch_unpadded_subsects(x0_list, padding_length, stride)\n",
    "x1 = batch_unpadded_subsects(x1_list, padding_length, stride)\n",
    "topo = np.swapaxes(batch_unpadded_subsects(topo_list, padding_length, stride), 1, 2)\n",
    "\n",
    "print(bx.shape)\n",
    "print(topo.shape)\n",
    "# shuffle the segments so they aren't adjacent to overlapping/similar segments NOT NEEDED bc dataloader shuffles\n",
    "# idx, s, bx, by, bz, ex, ey, ez, jy, x0, x1, topo = shuffle(idx, s, bx, by, bz, ex, ey, ez, jy, x0, x1, topo)\n",
    "\n",
    "# numpy arrays to torch tensors (while crying about how many lines of code this is surely there is a better way)\n",
    "idx = torch.from_numpy(idx).to(device, dtype=dtype)\n",
    "s = torch.from_numpy(s).to(device, dtype=dtype)\n",
    "bx = torch.from_numpy(bx).to(device, dtype=dtype)\n",
    "by = torch.from_numpy(by).to(device, dtype=dtype)\n",
    "bz = torch.from_numpy(bz).to(device, dtype=dtype)\n",
    "ex = torch.from_numpy(ex).to(device, dtype=dtype)\n",
    "ey = torch.from_numpy(ey).to(device, dtype=dtype)\n",
    "ez = torch.from_numpy(ez).to(device, dtype=dtype)\n",
    "jy = torch.from_numpy(jy).to(device, dtype=dtype)\n",
    "x0 = torch.from_numpy(x0).to(device, dtype=dtype)\n",
    "x1 = torch.from_numpy(x1).to(device, dtype=dtype)\n",
    "topo = torch.from_numpy(topo).to(device, dtype=dtype)\n",
    "print(bx.dtype)\n",
    "\n",
    "# collect data into Datasets\n",
    "sim_dset = TensorDataset(idx, s, bx, by, bz, ex, ey, ez, jy, x0, x1, topo)\n",
    "# Make DataLoaders for the training and test data\n",
    "sim_dl = DataLoader(sim_dset, batch_size = batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c452e90-9f14-4c70-9cc1-4bb6b5954dbb",
   "metadata": {},
   "source": [
    "### Garbage collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511087e-c555-4091-a4af-f49648645cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in topo_list:\n",
    "    del item\n",
    "    \n",
    "for item in topo_list_tmp:\n",
    "    del item\n",
    "    \n",
    "del topo_list\n",
    "del topo_list_tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
