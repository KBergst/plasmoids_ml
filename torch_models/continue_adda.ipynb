{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1fcdbd-531c-4df7-b83f-8c30ae45c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to continue training a good model\n",
    "# for now: /tigress/kendrab/analysis-notebooks/model_outs/20-09-24/adda_ndb190550_95mms_classifier_statedict.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6cb7bc-3596-4f44-a2b2-08e49f875cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset, ConcatDataset, DataLoader\n",
    "from  torch.nn.functional import one_hot\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import torchinfo\n",
    "import optuna\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "dtype = torch.double\n",
    "\n",
    "# Get functions from other notebooks\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/preproc_utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/eval_utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_mms_data.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/adda_constructor.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/ndb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca5f68e-cc7e-426c-9bfc-c7466ecd6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_classifier_path = \"/tigress/kendrab/analysis-notebooks/model_outs/20-09-24/adda_ndb190550_95mms_classifier_statedict.tar\"\n",
    "discriminator_path = \"/tigress/kendrab/analysis-notebooks/model_outs/20-09-24/adda_ndb190550_95discriminator_statedict.tar\"\n",
    "# some sim model hyperparameters\n",
    "padding_length = 39  # amount of data on each side of each segment for additional info\n",
    "stride = 11  # size (and therefore spacing) of each segment\n",
    "input_length = stride + 2*padding_length\n",
    "batch_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f4cd6c-21da-4041-9267-e2d630cc2104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "mms_epochs = 1  # number of times to loop through the entire mms dataset (start with 1 lmao)\n",
    "ndb_samples = 10000\n",
    "name='adda_ndb'\n",
    "\n",
    "# model parameters\n",
    "mms_kp_limit = 9  # not neeeded when loading from file\n",
    "mms_num_conv = 1\n",
    "mms_kernel_size = 3\n",
    "mms_pool_size = 4\n",
    "mms_out_channels = 40\n",
    "mms_learning_rate = 0.0012094769607738786\n",
    "mms_dropout_fraction = 0.03457536835651724\n",
    "discrim_width = 132\n",
    "discrim_length = 3\n",
    "\n",
    "rank = os.environ.get(\"OMPI_COMM_WORLD_RANK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a1b640-88df-4112-90de-6ee13b829905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kendrab/.conda/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# load a model\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_model.ipynb\n",
    "batch_size = 11\n",
    "# TODO?: enforce that key variables that need to exist later down the pipeline\n",
    "# are populated by import_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2a1675-937e-4d4b-bc92-4c2a3f9449d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the model's features (before classification step)\n",
    "# get_graph_node_names(model)\n",
    "return_nodes = {'post_merge_layers.2' : 'features'}\n",
    "feat_sim = create_feature_extractor(model, return_nodes=return_nodes)\n",
    "mock_data = torch.ones((batch_size, 1, input_length), dtype=dtype)\n",
    "tsum = torchinfo.summary(feat_sim, input_data = [mock_data for i in range(7)])\n",
    "feat_shape = tsum.summary_list[-1].output_size\n",
    "# extract the classifier part\n",
    "all_classifier = nn.Sequential(*list(model.children())[-1][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df18866e-31b0-4e1b-b3a5-a34f4b297b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425291, 1, 89)\n",
      "(425291, 2, 11)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Load the sim data\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_sim_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f3d0ef-e4f9-4c2b-9f3f-80e45aa1e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mms data locations and shuffle the files to not be chronological\n",
    "global_mms_filenames = get_filenames()\n",
    "debug_filename = \"2021-08-18T04-48-00_2021-08-20T04-30-30.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ed7cb2-03ce-43b0-9712-d7cd523e553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing stuff\n",
    "start = datetime.now(timezone.utc)  # for timing\n",
    "time_str = start.strftime(\"%H%M%S\")\n",
    "date_str = start.strftime(\"%d-%m-%y\")\n",
    "start_str = date_str + time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b29013-ebbf-4f3b-aafc-5736cc4ca1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the mms classifier\n",
    "class MMSModel(nn.Module):\n",
    "    def __init__(self, feat_extract, classifier):\n",
    "        super().__init__()\n",
    "        self.feat_extract = feat_extract\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, bx, by, bz, ex, ey, ez, jy):\n",
    "        features = self.feat_extract(bx, by, bz, ex, ey, ez, jy)\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a31d607-f021-461b-928c-48dc6d37cf52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "getting MMS file 2021-06-23T01-43-00_2021-06-23T02-18-00.h5, number 1 of 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kendrab/.conda/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components loaded in order ['B', 'E', 'j', 'time']\n",
      "training on 425291 source samples and 4744 target samples\n",
      "discrim loss: 5.689586079177939e-06, feat extract loss: 12.388117550885456, sample 550/4741\n",
      "discrim loss: 5.625089037738527e-07, feat extract loss: 14.51445509694881, sample 1100/4741\n",
      "discrim loss: 4.170218218072947e-07, feat extract loss: 14.736624571953216, sample 1650/4741\n",
      "discrim loss: 9.789309519908373e-07, feat extract loss: 13.889805374630013, sample 2200/4741\n",
      "discrim loss: 0.00016052788553176184, feat extract loss: 9.143181983814333, sample 2750/4741\n",
      "discrim loss: 0.005434739265688501, feat extract loss: 10.699710239587302, sample 3300/4741\n",
      "discrim loss: 0.0, feat extract loss: 38.74845349716259, sample 3850/4741\n",
      "discrim loss: 2.609288882559864e-09, feat extract loss: 19.61133155552098, sample 4400/4741\n",
      "Bin number 0 found statistically different with z-score 31.26526997403612 > 1.96\n",
      "Bin number 1 found statistically different with z-score 11.873790816689906 > 1.96\n",
      "Bin number 2 found statistically different with z-score 20.280222926669257 > 1.96\n",
      "Bin number 3 found statistically different with z-score 26.65268350376271 > 1.96\n",
      "Bin number 4 found statistically different with z-score 15.92525237554015 > 1.96\n",
      "Bin number 5 found statistically different with z-score 20.35944873341356 > 1.96\n",
      "Bin number 6 found statistically different with z-score 25.344925775716344 > 1.96\n",
      "Bin number 7 found statistically different with z-score 24.2004563253847 > 1.96\n",
      "Bin number 8 found statistically different with z-score 19.335468372588977 > 1.96\n",
      "Bin number 9 found statistically different with z-score 25.60902887513903 > 1.96\n",
      "Bin number 10 found statistically different with z-score 21.722724490770236 > 1.96\n",
      "Bin number 11 found statistically different with z-score 16.66751155383253 > 1.96\n",
      "Bin number 12 found statistically different with z-score 15.846570962186716 > 1.96\n",
      "Bin number 13 found statistically different with z-score 20.56090816457851 > 1.96\n",
      "Bin number 14 found statistically different with z-score 12.293636616536451 > 1.96\n",
      "Bin number 15 found statistically different with z-score 13.171637387608557 > 1.96\n",
      "Bin number 16 found statistically different with z-score 14.320669607838566 > 1.96\n",
      "Bin number 17 found statistically different with z-score 15.42057328523267 > 1.96\n",
      "Bin number 18 found statistically similar with z-score 1.000025000937539 < 1.96\n",
      "Bin number 19 found statistically different with z-score 26.632560811275656 > 1.96\n",
      "Bin number 20 found statistically different with z-score 25.13851593280247 > 1.96\n",
      "Bin number 21 found statistically different with z-score 15.354036801344147 > 1.96\n",
      "Bin number 22 found statistically different with z-score 138.92585673085458 > 1.96\n",
      "Bin number 23 found statistically different with z-score 26.41033794810208 > 1.96\n",
      "Bin number 24 found statistically different with z-score 19.795189561622394 > 1.96\n",
      "Saving model...\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MMSModel                                 --\n",
      "├─MMSFeatExtract: 1-1                    --\n",
      "│    └─Sequential: 2-1                   --\n",
      "│    │    └─Conv1d: 3-1                  160\n",
      "│    │    └─LeakyReLU: 3-2               --\n",
      "│    │    └─AvgPool1d: 3-3               --\n",
      "│    │    └─Dropout: 3-4                 --\n",
      "│    └─Sequential: 2-2                   --\n",
      "│    │    └─Conv1d: 3-5                  160\n",
      "│    │    └─LeakyReLU: 3-6               --\n",
      "│    │    └─AvgPool1d: 3-7               --\n",
      "│    │    └─Dropout: 3-8                 --\n",
      "│    └─Sequential: 2-3                   --\n",
      "│    │    └─Conv1d: 3-9                  160\n",
      "│    │    └─LeakyReLU: 3-10              --\n",
      "│    │    └─AvgPool1d: 3-11              --\n",
      "│    │    └─Dropout: 3-12                --\n",
      "│    └─Sequential: 2-4                   --\n",
      "│    │    └─Conv1d: 3-13                 160\n",
      "│    │    └─LeakyReLU: 3-14              --\n",
      "│    │    └─AvgPool1d: 3-15              --\n",
      "│    │    └─Dropout: 3-16                --\n",
      "│    └─Sequential: 2-5                   --\n",
      "│    │    └─Conv1d: 3-17                 160\n",
      "│    │    └─LeakyReLU: 3-18              --\n",
      "│    │    └─AvgPool1d: 3-19              --\n",
      "│    │    └─Dropout: 3-20                --\n",
      "│    └─Sequential: 2-6                   --\n",
      "│    │    └─Conv1d: 3-21                 160\n",
      "│    │    └─LeakyReLU: 3-22              --\n",
      "│    │    └─AvgPool1d: 3-23              --\n",
      "│    │    └─Dropout: 3-24                --\n",
      "│    └─Sequential: 2-7                   --\n",
      "│    │    └─Conv1d: 3-25                 160\n",
      "│    │    └─LeakyReLU: 3-26              --\n",
      "│    │    └─AvgPool1d: 3-27              --\n",
      "│    │    └─Dropout: 3-28                --\n",
      "│    └─Sequential: 2-8                   --\n",
      "│    │    └─Conv1d: 3-29                 9,680\n",
      "│    │    └─LeakyReLU: 3-30              --\n",
      "│    │    └─AvgPool1d: 3-31              --\n",
      "│    └─Sequential: 2-9                   --\n",
      "│    │    └─Flatten: 3-32                --\n",
      "│    │    └─Linear: 3-33                 69,336\n",
      "│    │    └─Unflatten: 3-34              --\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Flatten: 2-10                     --\n",
      "│    └─LazyLinear: 2-11                  2,387\n",
      "=================================================================\n",
      "Total params: 82,523\n",
      "Trainable params: 82,523\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "trial execution time (s): 68.159385\n"
     ]
    }
   ],
   "source": [
    "# rebuild the domain adaptation structure\n",
    "discrim, feat_mms = create_adda(mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate,\n",
    "                                mms_dropout_fraction, discrim_width, discrim_length, feat_shape)\n",
    "discrim.load_state_dict(torch.load(discriminator_path))\n",
    "mms_classifier = MMSModel(feat_mms, all_classifier)\n",
    "mms_classifier.load_state_dict(torch.load(mms_classifier_path))\n",
    "hyperparams_adda = {'num_conv': mms_num_conv, 'kp_limit': mms_kp_limit, 'kernel_size':mms_kernel_size, 'pool_size':mms_pool_size,\n",
    "                    'out_channels':mms_out_channels, 'learning_rate':mms_learning_rate, 'dropout_fraction':mms_dropout_fraction,\n",
    "                    'discrim_width':discrim_width, 'discrim_length':discrim_length, 'feat_shape':feat_shape}\n",
    "\n",
    "loss_fn_disc = nn.BCEWithLogitsLoss()\n",
    "loss_fn_feat = nn.BCEWithLogitsLoss()\n",
    "optim_disc = torch.optim.Adam(discrim.parameters(),lr=learning_rate)\n",
    "optim_feat = torch.optim.Adam(feat_mms.parameters(),lr=learning_rate)\n",
    "sum_loss_feat = 0\n",
    "sum_loss_disc = 0\n",
    "\n",
    "mms_filenames = global_mms_filenames\n",
    "for epoch in range(mms_epochs):\n",
    "    loss_feat = []\n",
    "    loss_disc = []\n",
    "    print(f\"Starting Epoch {epoch+1}\")\n",
    "    mms_filenames = shuffle(mms_filenames)\n",
    "    sim_iter = iter(sim_dl)  # to make sure we loop through the whole dataset before starting over even as we switch between mms files\n",
    "    for i, mms_file in enumerate(mms_filenames):\n",
    "        print(f\"getting MMS file {mms_file}, number {i+1} of {len(mms_filenames)}\")\n",
    "        # get the mms data from the file\n",
    "        mms_data_dict = get_mms_data(mms_file)\n",
    "        if len(mms_data_dict) == 0:  # data was not loaded, skip this file\n",
    "            continue\n",
    "        mms_dl = format_mms_data(mms_data_dict)         \n",
    "        training_step = train_adda(sim_dl, mms_dl, feat_sim, feat_mms, discrim, loss_fn_disc, loss_fn_feat, optim_disc,\n",
    "                                   optim_feat, iter_source = sim_iter)\n",
    "        sim_iter = training_step[\"iter_source\"]\n",
    "        loss_feat += training_step[\"loss_feat\"]\n",
    "        loss_disc += training_step[\"loss_disc\"]\n",
    "\n",
    "    sum_loss_feat = sum(loss_feat)\n",
    "    sum_loss_disc = sum(loss_disc)\n",
    "# calculate ndb score\n",
    "mms_features, _ = get_mms_features(feature_extractor=feat_mms, n=ndb_samples)\n",
    "ndb_sim_dl = DataLoader(sim_dset, batch_size = ndb_samples, shuffle=True, drop_last=True)\n",
    "ndb_sim_samples = next(iter(ndb_sim_dl))\n",
    "sim_features = get_sim_features(feature_extractor = feat_sim, samples = ndb_sim_samples, n = ndb_samples)[\"features\"]\n",
    "mms_features_flat = torch.flatten(mms_features, start_dim=1).detach()\n",
    "sim_features_flat = torch.flatten(sim_features, start_dim=1).detach()\n",
    "ndb = ndb_score(sim_features_flat, mms_features_flat)\n",
    "\n",
    "# save if we are retrieving a specific trial\n",
    "print(\"Saving model...\")  # DEBUG\n",
    "\n",
    "if rank is not None:\n",
    "    time_str += f\"_{rank}\"  # differentiate between mpi ranks that started at same second\n",
    "log_file, _, _, file_start = generic_outputs_structure(\"/tigress/kendrab/analysis-notebooks/model_outs/\",\n",
    "                                                        name, date_str, time_str)\n",
    "# Dump information to file\n",
    "with open(log_file, 'w') as log:\n",
    "    log.write(f\"MMS model {name} domain adapted on {start_str}\\n\")\n",
    "    log.write(f\"using model file {model_file}\\n\")\n",
    "    log.write(f\"Feature extractor loss: {sum_loss_feat}\\n\")\n",
    "    log.write(f\"Discriminator loss: {sum_loss_disc}\\n\")\n",
    "    log.write(f\"NDB score: {ndb}\\n\")\n",
    "    log.write(\"Hyperparameters:\\n\")\n",
    "    for key in hyperparams_adda.keys():\n",
    "        log.write(f\"{key}\\t\\t{hyperparams_adda[key]}\\n\")\n",
    "\n",
    "mms_classifier = MMSModel(feat_mms, all_classifier)\n",
    "print(torchinfo.summary(mms_classifier))\n",
    "torch.save(mms_classifier.state_dict(), file_start+\"mms_classifier_statedict.tar\")\n",
    "# save the discriminator\n",
    "torch.save(discrim.state_dict(), file_start+\"discriminator_statedict.tar\")              \n",
    "\n",
    "# trial ended\n",
    "end = datetime.now(timezone.utc)\n",
    "print(f\"trial execution time (s): {(end-start).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72164bb-04b0-447b-8d75-27e6d53547c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
