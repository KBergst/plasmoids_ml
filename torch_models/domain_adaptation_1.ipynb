{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9704d4-67e0-48fc-bea3-c8878a2fc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pareto with multi-objective hyperparameter optimization on feature extractor and discriminator losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59dbd5b0-b58f-4562-88e5-d54a2aae0d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# import gc  # debug that memory leak\n",
    "# import tracemalloc  # DEBUG THAT MEMORY LEAK\n",
    "import psutil  # :( mem leak\n",
    "import h5py\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset, ConcatDataset, DataLoader\n",
    "from  torch.nn.functional import one_hot\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import torchinfo\n",
    "import optuna\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "dtype = torch.double\n",
    "\n",
    "# Get functions from other notebooks\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/preproc_utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/eval_utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_mms_data.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/adda_constructor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0ee82cc-8e22-4d49-b146-cbbc154996c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "mms_epochs = 1  # number of times to loop through the entire mms dataset (start with 1 lmao)\n",
    "name='adda_1'\n",
    "\n",
    "rank = os.environ.get(\"OMPI_COMM_WORLD_RANK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15690aa3-6188-4ca4-9c7d-95c0ae87bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_model.ipynb\n",
    "batch_size = 11\n",
    "# TODO?: enforce that key variables that need to exist later down the pipeline\n",
    "# are populated by import_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64919069-602c-44e4-a6fe-5566f4dd5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Sequential                               --\n",
       "├─Flatten: 1-1                           --\n",
       "├─LazyLinear: 1-2                        2,387\n",
       "=================================================================\n",
       "Total params: 2,387\n",
       "Trainable params: 2,387\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the model's features (before classification step)\n",
    "# get_graph_node_names(model)\n",
    "return_nodes = {'post_merge_layers.2' : 'features'}\n",
    "feat_sim = create_feature_extractor(model, return_nodes=return_nodes)\n",
    "mock_data = torch.ones((batch_size, 1, input_length), dtype=dtype)\n",
    "tsum = torchinfo.summary(feat_sim, input_data = [mock_data for i in range(7)])\n",
    "feat_shape = tsum.summary_list[-1].output_size\n",
    "# extract the classifier part\n",
    "all_classifier = nn.Sequential(*list(model.children())[-1][-2:])\n",
    "torchinfo.summary(all_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1acad2fe-aa9e-4b61-9bc8-719b6cdee894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425291, 1, 89)\n",
      "(425291, 2, 11)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Load the sim data\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_sim_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afdf29a4-095b-4f40-b294-c059b7685b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mms data locations and shuffle the files to not be chronological\n",
    "global_mms_filenames = get_filenames()\n",
    "debug_filename = \"2021-08-18T04-48-00_2021-08-20T04-30-30.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604828d-fcbd-4689-9b48-8e338b880f5e",
   "metadata": {},
   "source": [
    "### Time to do some training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9f97e80-6159-41b0-905e-2881ffa624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # timing stuff\n",
    "    start = datetime.now(timezone.utc)  # for timing\n",
    "    time_str = start.strftime(\"%H%M%S\")\n",
    "    date_str = start.strftime(\"%d-%m-%y\")\n",
    "    start_str = date_str + time_str\n",
    "\n",
    "    # make suggestions\n",
    "    mms_num_conv = trial.suggest_int('num_conv', 1, 2)  # for separate layers but also for end layer (so really there are num_conv*2 layers)\n",
    "    mms_kp_limit = int(input_length**(1/(mms_num_conv+1)))  # a non-maximal upper bound on sizes to avoid running out of length\n",
    "    print(f\"kernel eqn limit kp={kp_limit}\")\n",
    "    min_pool_size=2\n",
    "    mms_kernel_size = trial.suggest_int('kernel_size', 2, min(mms_kp_limit - min_pool_size, 10))  # max size 10 or lower\n",
    "    mms_pool_size = trial.suggest_int('pool_size', min_pool_size, min(mms_kp_limit - mms_kernel_size, 5))\n",
    "    mms_out_channels = trial.suggest_int('out_channels', 8, 56)  # like 'filters' in keras\n",
    "    mms_learning_rate = trial.suggest_float('learning_rate', 0.001, 0.003, log=True)  # CANT CHANGE LOG NOW >:(\n",
    "    mms_dropout_fraction = trial.suggest_float('dropout', 0, 0.3)    \n",
    "    discrim_width = trial.suggest_int('discrim_width', 30, 200)\n",
    "    discrim_length = trial.suggest_int('discrim_length', 1, 3)  # number of layer for discrim\n",
    "    # build the domain adaptation structure\n",
    "    discrim, feat_mms = create_adda(mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate,\n",
    "                                    mms_dropout_fraction, discrim_width, discrim_length, feat_shape)\n",
    "    hyperparams_adda = {'mms_num_conv': mms_num_conv, 'mms_kp_limit': mms_kp_limit, 'mms_kernel_size':mms_kernel_size, 'mms_pool_size':mms_pool_size,\n",
    "                        'mms_out_channels':mms_out_channels, 'mms_learning_rate':mms_learning_rate, 'mms_dropout_fraction':mms_dropout_fraction,\n",
    "                        'discrim_width':discrim_width, 'discrim_length':discrim_length, 'feat_shape':feat_shape}\n",
    "\n",
    "    loss_fn_disc = nn.BCEWithLogitsLoss()\n",
    "    loss_fn_feat = nn.BCEWithLogitsLoss()\n",
    "    optim_disc = torch.optim.Adam(discrim.parameters(),lr=mms_learning_rate)\n",
    "    optim_feat = torch.optim.Adam(feat_mms.parameters(),lr=mms_learning_rate)\n",
    "    sum_loss_feat = 0\n",
    "    sum_loss_disc = 0\n",
    "\n",
    "    mms_filenames = global_mms_filenames\n",
    "    for epoch in range(mms_epochs):\n",
    "        loss_feat = []\n",
    "        loss_disc = []\n",
    "        print(f\"Starting Epoch {epoch+1}\")\n",
    "        mms_filenames = shuffle(mms_filenames)\n",
    "        sim_iter = iter(sim_dl)  # to make sure we loop through the whole dataset before starting over even as we switch between mms files\n",
    "        for i, mms_file in enumerate(mms_filenames):\n",
    "            print(f\"getting MMS file {mms_file}, number {i+1} of {len(mms_filenames)}\")\n",
    "            # get the mms data from the file\n",
    "            process = psutil.Process()  # start debug loop thingy\n",
    "#            print(process.memory_info().rss/1024/1024)\n",
    "            mms_data_dict = get_mms_data(mms_file)\n",
    "#            print(process.memory_info().rss/1024/1024)\n",
    "            if len(mms_data_dict) == 0:  # data was not loaded, skip this file\n",
    "                continue\n",
    "            mms_dl = format_mms_data(mms_data_dict)\n",
    "#            print(process.memory_info().rss/1024/1024)            \n",
    "            training_step = train_adda(sim_dl, mms_dl, feat_sim, feat_mms, discrim, loss_fn_disc, loss_fn_feat, optim_disc,\n",
    "                                       optim_feat, iter_source = sim_iter)\n",
    "            sim_iter = training_step[\"iter_source\"]\n",
    "            loss_feat = training_step[\"loss_feat\"]\n",
    "            loss_disc = training_step[\"loss_disc\"]\n",
    "\n",
    "        sum_loss_feat = sum(loss_feat)\n",
    "        sum_loss_disc = sum(loss_disc)\n",
    "        \n",
    "    # save if we are retrieving a specific trial\n",
    "    if study.user_attrs['save']:\n",
    "        print(\"Saving model...\")  # DEBUG\n",
    "\n",
    "        if rank is not None:\n",
    "            time_str += f\"_{rank}\"  # differentiate between mpi ranks that started at same second\n",
    "        log_file, _, _, file_start = generic_outputs_structure(\"/tigress/kendrab/analysis-notebooks/model_outs/\",\n",
    "                                                                name, date_str, time_str)\n",
    "        # Dump information to file\n",
    "        with open(log_file, 'w') as log:\n",
    "            log.write(f\"MMS model {name} domain adapted on {start_str}\\n\")\n",
    "            log.write(f\"using model file {model_file}\\n\")\n",
    "            log.write(f\"trial number: {trial.number}\\n\")\n",
    "            log.write(f\"Feature extractor loss: {sum_loss_feat}\\n\")\n",
    "            log.write(f\"Discriminator loss: {sum_loss_disc}\\n\")\n",
    "            log.write(\"Hyperparameters:\\n\")\n",
    "            for key in hyperparams_adda.keys():\n",
    "                log.write(f\"{key}\\t\\t{hyperparams_adda[key]}\\n\")\n",
    "                \n",
    "        # save the mms classifier\n",
    "        class MMSModel(nn.Module):\n",
    "            def __init__(self, feat_extract, classifier):\n",
    "                super().__init__()\n",
    "                self.feat_extract = feat_extract\n",
    "                self.classifier = classifier\n",
    "            \n",
    "            def forward(self, bx, by, bz, ex, ey, ez, jy):\n",
    "                features = self.feat_extract(bx, by, bz, ex, ey, ez, jy)\n",
    "                logits = self.classifier(features)\n",
    "                return logits\n",
    "            \n",
    "        mms_classifier = MMSModel(feat_mms, all_classifier)\n",
    "        print(torchinfo.summary(mms_classifier))\n",
    "        torch.save(mms_classifier.state_dict(), file_start+\"mms_classifier_statedict.tar\")\n",
    "        # save the discriminator\n",
    "        torch.save(discrim.state_dict(), file_start+\"discriminator_statedict.tar\")              \n",
    "    \n",
    "    # trial ended\n",
    "    end = datetime.now(timezone.utc)\n",
    "    print(f\"trial execution time (s): {(end-start).total_seconds()}\")\n",
    "    return sum_loss_feat, sum_loss_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a63e4ec-e85d-45a9-894b-9ff77f22ed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel eqn limit kp=9\n",
      "Starting Epoch 1\n",
      "getting MMS file 2018-08-01T03-11-30_2018-08-01T13-27-00.h5, number 1 of 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kendrab/.conda/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 425291 source samples and 11653 target samples\n",
      "discrim loss: 1.0857857435195781, feat extract loss: 1.601543583387228, sample 550/11649\n",
      "discrim loss: 1.2887329279343955, feat extract loss: 0.8786267068848208, sample 1100/11649\n",
      "discrim loss: 1.2022937773258702, feat extract loss: 1.1551961545679934, sample 1650/11649\n",
      "discrim loss: 1.3607939228796888, feat extract loss: 0.7027617843800104, sample 2200/11649\n",
      "discrim loss: 1.1666834678496474, feat extract loss: 0.8065674928514768, sample 2750/11649\n",
      "discrim loss: 1.502984491326018, feat extract loss: 1.187458661063554, sample 3300/11649\n",
      "discrim loss: 0.5212991568514973, feat extract loss: 2.1163111132067893, sample 3850/11649\n",
      "discrim loss: 0.859973149223936, feat extract loss: 1.2526019629726528, sample 4400/11649\n",
      "discrim loss: 0.571939807182406, feat extract loss: 1.7479786991783504, sample 4950/11649\n",
      "discrim loss: 0.8170270054001282, feat extract loss: 1.034019050211272, sample 5500/11649\n",
      "discrim loss: 1.2192400769317169, feat extract loss: 0.8042979578736109, sample 6050/11649\n",
      "discrim loss: 0.7722743811359366, feat extract loss: 1.2805499919411956, sample 6600/11649\n",
      "discrim loss: 0.7891071986908968, feat extract loss: 1.7716729995659302, sample 7150/11649\n",
      "discrim loss: 0.5107733016964806, feat extract loss: 2.0283201412054255, sample 7700/11649\n",
      "discrim loss: 10.39759498177128, feat extract loss: 0.2916888442387815, sample 8250/11649\n",
      "discrim loss: 1.2099138481121483, feat extract loss: 1.108769234141421, sample 8800/11649\n",
      "discrim loss: 1.0784806319935096, feat extract loss: 1.2365240624963247, sample 9350/11649\n",
      "discrim loss: 0.437700917529102, feat extract loss: 1.54628975853954, sample 9900/11649\n",
      "discrim loss: 0.27663828521926764, feat extract loss: 2.39491798531422, sample 10450/11649\n",
      "discrim loss: 0.49473535292208465, feat extract loss: 2.0719658603665163, sample 11000/11649\n",
      "discrim loss: 0.48463093064995344, feat extract loss: 2.0161968598974895, sample 11550/11649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-16 10:39:53,027] Trial 3511 finished with values: {'sum_loss_feat': 1.9338242634912497, 'sum_loss_disc': 0.5537149665738788} and parameters: {'num_conv': 2, 'kernel_size': 2, 'pool_size': 2, 'out_channels': 31, 'learning_rate': 0.001057022133105261, 'dropout': 0.04152485670069086, 'discrim_width': 88, 'discrim_length': 3}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MMSModel                                 --\n",
      "├─MMSFeatExtract: 1-1                    --\n",
      "│    └─Sequential: 2-1                   --\n",
      "│    │    └─Conv1d: 3-1                  93\n",
      "│    │    └─LeakyReLU: 3-2               --\n",
      "│    │    └─AvgPool1d: 3-3               --\n",
      "│    │    └─Dropout: 3-4                 --\n",
      "│    │    └─Conv1d: 3-5                  1,953\n",
      "│    │    └─LeakyReLU: 3-6               --\n",
      "│    │    └─AvgPool1d: 3-7               --\n",
      "│    │    └─Dropout: 3-8                 --\n",
      "│    └─Sequential: 2-2                   --\n",
      "│    │    └─Conv1d: 3-9                  93\n",
      "│    │    └─LeakyReLU: 3-10              --\n",
      "│    │    └─AvgPool1d: 3-11              --\n",
      "│    │    └─Dropout: 3-12                --\n",
      "│    │    └─Conv1d: 3-13                 1,953\n",
      "│    │    └─LeakyReLU: 3-14              --\n",
      "│    │    └─AvgPool1d: 3-15              --\n",
      "│    │    └─Dropout: 3-16                --\n",
      "│    └─Sequential: 2-3                   --\n",
      "│    │    └─Conv1d: 3-17                 93\n",
      "│    │    └─LeakyReLU: 3-18              --\n",
      "│    │    └─AvgPool1d: 3-19              --\n",
      "│    │    └─Dropout: 3-20                --\n",
      "│    │    └─Conv1d: 3-21                 1,953\n",
      "│    │    └─LeakyReLU: 3-22              --\n",
      "│    │    └─AvgPool1d: 3-23              --\n",
      "│    │    └─Dropout: 3-24                --\n",
      "│    └─Sequential: 2-4                   --\n",
      "│    │    └─Conv1d: 3-25                 93\n",
      "│    │    └─LeakyReLU: 3-26              --\n",
      "│    │    └─AvgPool1d: 3-27              --\n",
      "│    │    └─Dropout: 3-28                --\n",
      "│    │    └─Conv1d: 3-29                 1,953\n",
      "│    │    └─LeakyReLU: 3-30              --\n",
      "│    │    └─AvgPool1d: 3-31              --\n",
      "│    │    └─Dropout: 3-32                --\n",
      "│    └─Sequential: 2-5                   --\n",
      "│    │    └─Conv1d: 3-33                 93\n",
      "│    │    └─LeakyReLU: 3-34              --\n",
      "│    │    └─AvgPool1d: 3-35              --\n",
      "│    │    └─Dropout: 3-36                --\n",
      "│    │    └─Conv1d: 3-37                 1,953\n",
      "│    │    └─LeakyReLU: 3-38              --\n",
      "│    │    └─AvgPool1d: 3-39              --\n",
      "│    │    └─Dropout: 3-40                --\n",
      "│    └─Sequential: 2-6                   --\n",
      "│    │    └─Conv1d: 3-41                 93\n",
      "│    │    └─LeakyReLU: 3-42              --\n",
      "│    │    └─AvgPool1d: 3-43              --\n",
      "│    │    └─Dropout: 3-44                --\n",
      "│    │    └─Conv1d: 3-45                 1,953\n",
      "│    │    └─LeakyReLU: 3-46              --\n",
      "│    │    └─AvgPool1d: 3-47              --\n",
      "│    │    └─Dropout: 3-48                --\n",
      "│    └─Sequential: 2-7                   --\n",
      "│    │    └─Conv1d: 3-49                 93\n",
      "│    │    └─LeakyReLU: 3-50              --\n",
      "│    │    └─AvgPool1d: 3-51              --\n",
      "│    │    └─Dropout: 3-52                --\n",
      "│    │    └─Conv1d: 3-53                 1,953\n",
      "│    │    └─LeakyReLU: 3-54              --\n",
      "│    │    └─AvgPool1d: 3-55              --\n",
      "│    │    └─Dropout: 3-56                --\n",
      "│    └─Sequential: 2-8                   --\n",
      "│    │    └─Conv1d: 3-57                 3,906\n",
      "│    │    └─LeakyReLU: 3-58              --\n",
      "│    │    └─AvgPool1d: 3-59              --\n",
      "│    └─Sequential: 2-9                   --\n",
      "│    │    └─Flatten: 3-60                --\n",
      "│    │    └─Linear: 3-61                 134,136\n",
      "│    │    └─Unflatten: 3-62              --\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Flatten: 2-10                     --\n",
      "│    └─LazyLinear: 2-11                  2,387\n",
      "=================================================================\n",
      "Total params: 154,751\n",
      "Trainable params: 154,751\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "trial execution time (s): 41.367018\n"
     ]
    }
   ],
   "source": [
    "# assume study already made\n",
    "\"\"\" study = optuna.create_study(study_name='adda_optim',storage=\"mysql+mysqldb://optunauser:Frikkenoptuna@stellar-intel.princeton.edu:47793/adda_1\", directions=['minimize','minimize'])\"\"\"\n",
    "# use hyperband pruner \n",
    "study = optuna.load_study(study_name='adda_optim',storage=\"mysql+mysqldb://optunauser:Frikkenoptuna@stellar-intel.princeton.edu:47793/adda_1\")\n",
    "# # regular training\n",
    "# study.set_user_attr('save',False)\n",
    "# study.optimize(objective, n_trials=10)\n",
    "# bringing back the best one to train a new model\n",
    "trial_num = study.user_attrs['knee_trial_num']\n",
    "best_params = study.trials[trial_num].params\n",
    "study.enqueue_trial(best_params, skip_if_exists=False)\n",
    "study.set_user_attr('save',True)\n",
    "study.optimize(objective, n_trials=4)\n",
    "# objective(study.trials[trial_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7cb2efe-1a87-4e8d-81ad-895a57eb9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the loss\n",
    "# fig, ax = plt.subplots(2)\n",
    "# ax[0].plot(loss_disc)\n",
    "# ax[1].plot(loss_feat)\n",
    "# ax[0].set(title=\"Discriminator loss\", xlabel=\"training iteration\", ylabel=\"loss\")\n",
    "# ax[1].set(title=\"MMS Feature Extractor loss\", xlabel=\"training iteration\", ylabel=\"loss\")\n",
    "# fig.savefig(\"/tigress/kendrab/analysis-notebooks/model_outs/scratchwork/training_losses.svg\")  # TODO: save model and training info to its own folder\n",
    "# plt.close(fig='all')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c782a80-444d-479c-91a8-1ddcaca29149",
   "metadata": {},
   "source": [
    "Starting Epoch 1\n",
    "getting MMS file 2020-07-15T20-25-30_2020-07-16T00-04-00.h5, number 1 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "2407.25\n",
    "2659.3125\n",
    "2716.8125\n",
    "getting MMS file 2019-08-13T17-50-30_2019-08-13T19-38-30.h5, number 2 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "2716.875\n",
    "3013.0\n",
    "2884.5\n",
    "getting MMS file 2021-07-14T15-33-30_2021-07-14T23-55-00.h5, number 3 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "2884.5\n",
    "3098.0\n",
    "3075.9375\n",
    "getting MMS file 2018-08-08T08-44-30_2018-08-08T18-17-30.h5, number 4 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "3075.9375\n",
    "3330.75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
