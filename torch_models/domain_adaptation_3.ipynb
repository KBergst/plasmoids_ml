{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e9704d4-67e0-48fc-bea3-c8878a2fc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no ADDA or critic, just distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59dbd5b0-b58f-4562-88e5-d54a2aae0d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import psutil  # :( mem leak\n",
    "import h5py\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset, ConcatDataset, DataLoader\n",
    "from  torch.nn.functional import one_hot\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import torchinfo\n",
    "import optuna\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "dtype = torch.double\n",
    "\n",
    "# Get functions from other notebooks\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/preproc_utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/eval_utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_mms_data.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/ndb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de81af5-a31c-40c6-a6b4-2a476421e273",
   "metadata": {},
   "source": [
    "### Helupful functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c592c52-1ad3-4e8f-bed7-2edf434641b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dl_source, dl_target, feat_extract_source, feat_extract_target, loss_fn, optimizer, iter_source=None):\n",
    "    # note feat_extract_source is a special boye that returns a dictionary that we need to get a value from\n",
    "    inter_iteration_stuff = {}  # whatever I need to escape this function (losses over time, the current iterator, etc.)\n",
    "    feat_extract_source.eval()\n",
    "    batch_size = dl_source.batch_size  # the length of a tensordataset is the batch size (shared first dim)\n",
    "    \n",
    "    # let's iterate enough that the mms dataset is completely used. \n",
    "    samples_source = len(dl_source.dataset)\n",
    "    samples_target = len(dl_target.dataset)\n",
    "    total_batches =samples_target//batch_size\n",
    "    print(f\"training on {samples_source} source samples and {samples_target} target samples\")\n",
    "    # iterate\n",
    "    if iter_source is None:  # make the source iterator if it doesn't already exist\n",
    "        print(\"Making source iterator\")  # shouldn't ever fire with current setup / needs from the code\n",
    "        iter_source = iter(dl_source)\n",
    "    iter_target = iter(dl_target)\n",
    "    for batch in range(total_batches):\n",
    "        ds_source, iter_source = iter_or_restart_dl(dl_source, iter_source)\n",
    "        ds_target, iter_target = iter_or_restart_dl(dl_target, iter_target)\n",
    "        loss_feat = []\n",
    "        # unpack values\n",
    "        _, _, bx_s, by_s, bz_s, ex_s, ey_s, ez_s, jy_s, _, _, _ = ds_source\n",
    "        bx_t, by_t, bz_t, ex_t, ey_t, ez_t, _, jy_t, _, _ = ds_target\n",
    "        # calculate features, add labels\n",
    "        feat_source = feat_extract_source(bx_s, by_s, bz_s, ex_s, ey_s, ez_s, jy_s)[\"features\"].detach()  # don't calc gradient\n",
    "        feat_target = feat_extract_target(bx_t, by_t, bz_t, ex_t, ey_t, ez_t, jy_t)\n",
    "        \n",
    "        feat_extract_target.train()\n",
    "        optimizer.zero_grad()\n",
    "        # put features into spaces the loss fn expects\n",
    "        logsm_feat_target = nn.functional.log_softmax(feat_target, dim=-1)\n",
    "        logsm_feat_source = nn.functional.log_softmax(feat_source, dim=-1)\n",
    "        lossF = loss_fn(logsm_feat_target, logsm_feat_source)  # pred, true\n",
    "        lossF.backward()\n",
    "        optimizer.step() \n",
    "        loss_feat.append(lossF.item())\n",
    "\n",
    "        if (batch+1) % 50 == 0:\n",
    "            current_sample = (batch+1)*batch_size\n",
    "            print(f\"feat extract loss: {lossF}, sample {current_sample}/{total_batches*batch_size}\")\n",
    "    # configure function outputs \n",
    "    inter_iteration_stuff[\"iter_source\"] = iter_source\n",
    "    if \"loss_feat\" not in inter_iteration_stuff:\n",
    "        inter_iteration_stuff[\"loss_feat\"] = [] \n",
    "    inter_iteration_stuff[\"loss_feat\"] += loss_feat\n",
    "    \n",
    "    return inter_iteration_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48056c7f-084d-4d4f-9bdf-d58ba0f97444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_layers_n_times(layer_list, n):  # this instead of something simpler to be absolutely sure the layers are different objects and not repeating the same one\n",
    "    new_layer_list = []\n",
    "    for i in range(n):\n",
    "        for layer in layer_list:\n",
    "            new_layer_list.append(copy.deepcopy(layer))\n",
    "    return new_layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59a96fa8-ddd0-423d-98e9-3cf8ee572809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMSFeatExtract(nn.Module): #TODO: strided convolution instead of pooling?\n",
    "    \"\"\" 1D CNN Model \"\"\"\n",
    "    def __init__(self, mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate, mms_dropout_fraction, feat_shape):\n",
    "        super().__init__()\n",
    "        # define these all separately because they will get different weights\n",
    "        # consider smooshing these together into one convolution with in_channels=6. Idk if a good idea\n",
    "        feat_shape_nobatch = feat_shape[1:]\n",
    "        self.bx_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.by_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.bz_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.ex_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.ey_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.ez_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        self.jy_layers = nn.Sequential(*repeat_layers_n_times([nn.LazyConv1d(mms_out_channels, mms_kernel_size, padding='valid'),\n",
    "                                           nn.LeakyReLU(), nn.AvgPool1d(mms_pool_size), nn.Dropout(p=mms_dropout_fraction)], mms_num_conv))\n",
    "        \n",
    "        self.post_merge_layers = nn.Sequential(nn.Conv1d(mms_out_channels, mms_out_channels*2, mms_kernel_size,\n",
    "                                                         padding='valid'),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.AvgPool1d(mms_pool_size))\n",
    "        self.resize_features = nn.Sequential(nn.Flatten(), nn.LazyLinear(np.prod(feat_shape_nobatch)), nn.Unflatten(-1, feat_shape_nobatch))\n",
    "                                               \n",
    "\n",
    "    def forward(self, bx, by, bz, ex, ey, ez, jy):\n",
    "        bx_proc = self.bx_layers(bx)\n",
    "        by_proc = self.by_layers(by)\n",
    "        bz_proc = self.bz_layers(bz)\n",
    "        ex_proc = self.ex_layers(ex)\n",
    "        ey_proc = self.ey_layers(ey)\n",
    "        ez_proc = self.ez_layers(ez)\n",
    "        jy_proc = self.jy_layers(jy)\n",
    "        combined = (bx_proc + by_proc + bz_proc + ex_proc + ey_proc + ez_proc + jy_proc)/6.\n",
    "        mms_features = self.post_merge_layers(combined)\n",
    "        features = self.resize_features(mms_features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3820f-0971-4d10-ab82-14fe98134123",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0ee82cc-8e22-4d49-b146-cbbc154996c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "mms_epochs = 1  # number of times to loop through the entire mms dataset (start with 1 lmao)\n",
    "ndb_samples = 10000\n",
    "name='da_dist'\n",
    "\n",
    "rank = os.environ.get(\"OMPI_COMM_WORLD_RANK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15690aa3-6188-4ca4-9c7d-95c0ae87bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kendrab/.conda/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# load a model\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_model.ipynb\n",
    "batch_size = 64\n",
    "# TODO?: enforce that key variables that need to exist later down the pipeline\n",
    "# are populated by import_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64919069-602c-44e4-a6fe-5566f4dd5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Sequential                               --\n",
       "├─Flatten: 1-1                           --\n",
       "├─LazyLinear: 1-2                        2,387\n",
       "=================================================================\n",
       "Total params: 2,387\n",
       "Trainable params: 2,387\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the model's features (before classification step)\n",
    "# get_graph_node_names(model)\n",
    "return_nodes = {'post_merge_layers.2' : 'features'}\n",
    "feat_sim = create_feature_extractor(model, return_nodes=return_nodes)\n",
    "mock_data = torch.ones((batch_size, 1, input_length), dtype=dtype)\n",
    "tsum = torchinfo.summary(feat_sim, input_data = [mock_data for i in range(7)])\n",
    "feat_shape = tsum.summary_list[-1].output_size\n",
    "# extract the classifier part\n",
    "all_classifier = nn.Sequential(*list(model.children())[-1][-2:])\n",
    "torchinfo.summary(all_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1acad2fe-aa9e-4b61-9bc8-719b6cdee894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425291, 1, 89)\n",
      "(425291, 2, 11)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Load the sim data\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_sim_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afdf29a4-095b-4f40-b294-c059b7685b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mms data locations and shuffle the files to not be chronological\n",
    "global_mms_filenames = get_filenames()\n",
    "debug_filename = \"2021-08-18T04-48-00_2021-08-20T04-30-30.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604828d-fcbd-4689-9b48-8e338b880f5e",
   "metadata": {},
   "source": [
    "### Time to do some training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9f97e80-6159-41b0-905e-2881ffa624d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # timing stuff\n",
    "    start = datetime.now(timezone.utc)  # for timing\n",
    "    time_str = start.strftime(\"%H%M%S\")\n",
    "    date_str = start.strftime(\"%d-%m-%y\")\n",
    "    start_str = date_str + time_str\n",
    "\n",
    "    # make suggestions\n",
    "    mms_num_conv = trial.suggest_int('num_conv', 1, 2)  # for separate layers but also for end layer (so really there are num_conv*2 layers)\n",
    "    mms_kp_limit = int(input_length**(1/(mms_num_conv+1)))  # a non-maximal upper bound on sizes to avoid running out of length\n",
    "    print(f\"kernel eqn limit kp={kp_limit}\")\n",
    "    min_pool_size=2\n",
    "    mms_kernel_size = trial.suggest_int('kernel_size', 2, min(mms_kp_limit - min_pool_size, 10))  # max size 10 or lower\n",
    "    mms_pool_size = trial.suggest_int('pool_size', min_pool_size, min(mms_kp_limit - mms_kernel_size, 5))\n",
    "    mms_out_channels = trial.suggest_int('out_channels', 8, 56)  # like 'filters' in keras\n",
    "    mms_learning_rate = trial.suggest_float('learning_rate', 0.001, 0.003, log=True)  # CANT CHANGE LOG NOW >:(\n",
    "    mms_dropout_fraction = trial.suggest_float('dropout', 0, 0.3)    \n",
    "\n",
    "    hyperparams = {'mms_num_conv': mms_num_conv, 'mms_kp_limit': mms_kp_limit, 'mms_kernel_size':mms_kernel_size, 'mms_pool_size':mms_pool_size,\n",
    "                        'mms_out_channels':mms_out_channels, 'mms_learning_rate':mms_learning_rate, 'mms_dropout_fraction':mms_dropout_fraction,\n",
    "                        'feat_shape':feat_shape}\n",
    "\n",
    "    mms_filenames = global_mms_filenames\n",
    "    \n",
    "    # make the boyes\n",
    "    feat_mms = MMSFeatExtract(mms_num_conv, mms_kp_limit, mms_kernel_size, mms_pool_size, mms_out_channels, mms_learning_rate,\n",
    "                              mms_dropout_fraction, feat_shape).to(device=device, dtype=torch.double)\n",
    "    loss_fn = torch.nn.KLDivLoss(reduction= 'batchmean', log_target=True)\n",
    "    opt = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "    sum_loss_feat = 0\n",
    "    \n",
    "    for epoch in range(mms_epochs):\n",
    "        loss_feat = []\n",
    "        print(f\"Starting Epoch {epoch+1}\")\n",
    "        mms_filenames = shuffle(mms_filenames)\n",
    "        sim_iter = iter(sim_dl)  # to make sure we loop through the whole dataset before starting over even as we switch between mms files\n",
    "        for i, mms_file in enumerate(mms_filenames):\n",
    "            print(f\"getting MMS file {mms_file}, number {i+1} of {len(mms_filenames)}\")\n",
    "            mms_data_dict = get_mms_data(mms_file)\n",
    "            if len(mms_data_dict) == 0:  # data was not loaded, skip this file\n",
    "                continue\n",
    "            mms_dl = format_mms_data(mms_data_dict)\n",
    "            \n",
    "            training_step = train(sim_dl, mms_dl, feat_sim, feat_mms, loss_fn, opt, iter_source=sim_iter)\n",
    "            sim_iter = training_step[\"iter_source\"]\n",
    "            loss_feat += training_step[\"loss_feat\"]\n",
    "            \n",
    "        sum_loss_feat = sum(loss_feat)  \n",
    "\n",
    "    # calculate ndb score\n",
    "    mms_features, _ = get_mms_features(feature_extractor=feat_mms, n=ndb_samples)\n",
    "    ndb_sim_dl = DataLoader(sim_dset, batch_size = ndb_samples, shuffle=True, drop_last=True)\n",
    "    ndb_sim_samples = next(iter(ndb_sim_dl))\n",
    "    sim_features = get_sim_features(feature_extractor = feat_sim, samples = ndb_sim_samples, n = ndb_samples)[\"features\"]\n",
    "    mms_features_flat = torch.flatten(mms_features, start_dim=1).detach()\n",
    "    sim_features_flat = torch.flatten(sim_features, start_dim=1).detach()\n",
    "    ndb = ndb_score(sim_features_flat, mms_features_flat)\n",
    "    \n",
    "    # save if we are retrieving a specific trial\n",
    "    if study.user_attrs['save']:\n",
    "        print(\"Saving model...\")  # DEBUG\n",
    "\n",
    "        if rank is not None:\n",
    "            time_str += f\"_{rank}\"  # differentiate between mpi ranks that started at same second\n",
    "        log_file, _, _, file_start = generic_outputs_structure(\"/tigress/kendrab/analysis-notebooks/model_outs/\",\n",
    "                                                                name, date_str, time_str)\n",
    "        # Dump information to file\n",
    "        with open(log_file, 'w') as log:\n",
    "            log.write(f\"MMS model {name} domain adapted on {start_str}\\n\")\n",
    "            log.write(f\"using model file {model_file}\\n\")\n",
    "            log.write(f\"trial number: {trial.number}\\n\")\n",
    "            log.write(f\"Feature extractor loss: {sum_loss_feat}\\n\")\n",
    "            log.write(f\"NDB score: {ndb}\\n\")\n",
    "            log.write(\"Hyperparameters:\\n\")\n",
    "            for key in hyperparams.keys():\n",
    "                log.write(f\"{key}\\t\\t{hyperparams[key]}\\n\")\n",
    "                \n",
    "        # save the mms classifier\n",
    "        class MMSModel(nn.Module):\n",
    "            def __init__(self, feat_extract, classifier):\n",
    "                super().__init__()\n",
    "                self.feat_extract = feat_extract\n",
    "                self.classifier = classifier\n",
    "            \n",
    "            def forward(self, bx, by, bz, ex, ey, ez, jy):\n",
    "                features = self.feat_extract(bx, by, bz, ex, ey, ez, jy)\n",
    "                logits = self.classifier(features)\n",
    "                return logits\n",
    "            \n",
    "        mms_classifier = MMSModel(feat_mms, all_classifier)\n",
    "        print(torchinfo.summary(mms_classifier))\n",
    "        torch.save(mms_classifier.state_dict(), file_start+\"mms_classifier_statedict.tar\")             \n",
    "    \n",
    "    # trial ended\n",
    "    end = datetime.now(timezone.utc)\n",
    "    print(f\"trial execution time (s): {(end-start).total_seconds()}\")\n",
    "    return ndb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb70a0-166b-43a8-858e-bc19fe4e445c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "317a58de-91fe-4b15-85d1-df897b175143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel eqn limit kp=9\n",
      "Starting Epoch 1\n",
      "getting MMS file 2017-07-07T19-35-30_2017-07-08T01-30-30.h5, number 1 of 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kendrab/.conda/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components loaded in order ['B', 'E', 'j', 'time']\n",
      "training on 425291 source samples and 1704 target samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 10:48:09,102] Trial 2 finished with value: 0.96 and parameters: {'num_conv': 1, 'kernel_size': 7, 'pool_size': 2, 'out_channels': 19, 'learning_rate': 0.0012192174762584518, 'dropout': 0.2637361201158373}. Best is trial 1 with value: 0.92.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin number 0 found statistically different with z-score 20.433762886797137 > 1.96\n",
      "Bin number 1 found statistically different with z-score 14.742332445504958 > 1.96\n",
      "Bin number 2 found statistically different with z-score 26.632560811275656 > 1.96\n",
      "Bin number 3 found statistically different with z-score 24.50519766019962 > 1.96\n",
      "Bin number 4 found statistically different with z-score 25.504714253411414 > 1.96\n",
      "Bin number 5 found statistically different with z-score 21.91488415108522 > 1.96\n",
      "Bin number 6 found statistically different with z-score 18.14759572885496 > 1.96\n",
      "Bin number 7 found statistically different with z-score 16.23035793640016 > 1.96\n",
      "Bin number 8 found statistically different with z-score 25.837226264274413 > 1.96\n",
      "Bin number 9 found statistically different with z-score 13.702045035498896 > 1.96\n",
      "Bin number 10 found statistically different with z-score 129.074595187125 > 1.96\n",
      "Bin number 11 found statistically different with z-score 12.937902900046966 > 1.96\n",
      "Bin number 12 found statistically different with z-score 18.37400963920722 > 1.96\n",
      "Bin number 13 found statistically similar with z-score 1.7321807259954505 < 1.96\n",
      "Bin number 14 found statistically different with z-score 2.0002000300050007 > 1.96\n",
      "Bin number 15 found statistically different with z-score 25.588195667400374 > 1.96\n",
      "Bin number 16 found statistically different with z-score 22.176638128637187 > 1.96\n",
      "Bin number 17 found statistically different with z-score 24.244198313954524 > 1.96\n",
      "Bin number 18 found statistically different with z-score 11.43899158295111 > 1.96\n",
      "Bin number 19 found statistically different with z-score 26.992789127287068 > 1.96\n",
      "Bin number 20 found statistically different with z-score 9.074005956290122 > 1.96\n",
      "Bin number 21 found statistically different with z-score 15.814189645302708 > 1.96\n",
      "Bin number 22 found statistically different with z-score 15.186479926805514 > 1.96\n",
      "Bin number 23 found statistically different with z-score 19.83926436960382 > 1.96\n",
      "Bin number 24 found statistically different with z-score 27.25040414437818 > 1.96\n",
      "Saving model...\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MMSModel                                 --\n",
      "├─MMSFeatExtract: 1-1                    --\n",
      "│    └─Sequential: 2-1                   --\n",
      "│    │    └─Conv1d: 3-1                  152\n",
      "│    │    └─LeakyReLU: 3-2               --\n",
      "│    │    └─AvgPool1d: 3-3               --\n",
      "│    │    └─Dropout: 3-4                 --\n",
      "│    └─Sequential: 2-2                   --\n",
      "│    │    └─Conv1d: 3-5                  152\n",
      "│    │    └─LeakyReLU: 3-6               --\n",
      "│    │    └─AvgPool1d: 3-7               --\n",
      "│    │    └─Dropout: 3-8                 --\n",
      "│    └─Sequential: 2-3                   --\n",
      "│    │    └─Conv1d: 3-9                  152\n",
      "│    │    └─LeakyReLU: 3-10              --\n",
      "│    │    └─AvgPool1d: 3-11              --\n",
      "│    │    └─Dropout: 3-12                --\n",
      "│    └─Sequential: 2-4                   --\n",
      "│    │    └─Conv1d: 3-13                 152\n",
      "│    │    └─LeakyReLU: 3-14              --\n",
      "│    │    └─AvgPool1d: 3-15              --\n",
      "│    │    └─Dropout: 3-16                --\n",
      "│    └─Sequential: 2-5                   --\n",
      "│    │    └─Conv1d: 3-17                 152\n",
      "│    │    └─LeakyReLU: 3-18              --\n",
      "│    │    └─AvgPool1d: 3-19              --\n",
      "│    │    └─Dropout: 3-20                --\n",
      "│    └─Sequential: 2-6                   --\n",
      "│    │    └─Conv1d: 3-21                 152\n",
      "│    │    └─LeakyReLU: 3-22              --\n",
      "│    │    └─AvgPool1d: 3-23              --\n",
      "│    │    └─Dropout: 3-24                --\n",
      "│    └─Sequential: 2-7                   --\n",
      "│    │    └─Conv1d: 3-25                 152\n",
      "│    │    └─LeakyReLU: 3-26              --\n",
      "│    │    └─AvgPool1d: 3-27              --\n",
      "│    │    └─Dropout: 3-28                --\n",
      "│    └─Sequential: 2-8                   --\n",
      "│    │    └─Conv1d: 3-29                 5,092\n",
      "│    │    └─LeakyReLU: 3-30              --\n",
      "│    │    └─AvgPool1d: 3-31              --\n",
      "│    └─Sequential: 2-9                   --\n",
      "│    │    └─Flatten: 3-32                --\n",
      "│    │    └─Linear: 3-33                 139,752\n",
      "│    │    └─Unflatten: 3-34              --\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Flatten: 2-10                     --\n",
      "│    └─LazyLinear: 2-11                  2,387\n",
      "=================================================================\n",
      "Total params: 148,295\n",
      "Trainable params: 148,295\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "trial execution time (s): 128.542562\n"
     ]
    }
   ],
   "source": [
    "# assume study already made\n",
    "\"\"\" study = optuna.create_study(study_name='da_discrep2',storage=\"mysql+mysqldb://optunauser:Frikkenoptuna@stellar-intel.princeton.edu:47793/da_discrep\", direction='minimize')\"\"\"\n",
    "study = optuna.load_study(study_name='da_discrep2',storage=\"mysql+mysqldb://optunauser:Frikkenoptuna@stellar-intel.princeton.edu:47793/da_discrep\")\n",
    "# regular training with saving models\n",
    "study.set_user_attr('save', True)\n",
    "study.optimize(objective, n_trials=1)\n",
    "# # bringing back the best one to train a new model\n",
    "# trial_num = study.user_attrs['knee_trial_num']\n",
    "# best_params = study.trials[trial_num].params\n",
    "# study.enqueue_trial(best_params, skip_if_exists=False)\n",
    "# study.set_user_attr('save',True)\n",
    "# study.optimize(objective, n_trials=4)\n",
    "# objective(study.trials[trial_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7cb2efe-1a87-4e8d-81ad-895a57eb9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the loss\n",
    "# fig, ax = plt.subplots(2)\n",
    "# ax[0].plot(loss_disc)\n",
    "# ax[1].plot(loss_feat)\n",
    "# ax[0].set(title=\"Discriminator loss\", xlabel=\"training iteration\", ylabel=\"loss\")\n",
    "# ax[1].set(title=\"MMS Feature Extractor loss\", xlabel=\"training iteration\", ylabel=\"loss\")\n",
    "# fig.savefig(\"/tigress/kendrab/analysis-notebooks/model_outs/scratchwork/training_losses.svg\")  # TODO: save model and training info to its own folder\n",
    "# plt.close(fig='all')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c782a80-444d-479c-91a8-1ddcaca29149",
   "metadata": {},
   "source": [
    "Starting Epoch 1\n",
    "getting MMS file 2020-07-15T20-25-30_2020-07-16T00-04-00.h5, number 1 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "2407.25\n",
    "2659.3125\n",
    "2716.8125\n",
    "getting MMS file 2019-08-13T17-50-30_2019-08-13T19-38-30.h5, number 2 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "2716.875\n",
    "3013.0\n",
    "2884.5\n",
    "getting MMS file 2021-07-14T15-33-30_2021-07-14T23-55-00.h5, number 3 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "2884.5\n",
    "3098.0\n",
    "3075.9375\n",
    "getting MMS file 2018-08-08T08-44-30_2018-08-08T18-17-30.h5, number 4 of 230\n",
    "overridden with debug file 2021-08-18T04-48-00_2021-08-20T04-30-30.h5\n",
    "3075.9375\n",
    "3330.75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
