{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8851c4d-00ba-4d05-a546-c5c7c2be3770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torchinfo\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torcheval.metrics as tem  # YAY METRICS\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import optuna\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "dtype = torch.double\n",
    "\n",
    "# Get functions from other notebooks\n",
    "%run /tigress/kendrab/analysis-notebooks/preproc_utils.ipynb\n",
    "%run /tigress/kendrab/analysis-notebooks/eval_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d23ee67-4e96-4c82-9760-83ca659cb014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kendrab/.conda/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# load a model\n",
    "%run /tigress/kendrab/analysis-notebooks/torch_models/import_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54517a96-2e12-4c0c-8a51-93dc3db331a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_start = \"/tigress/kendrab/analysis-notebooks/model_outs/scratchwork/14-06-24F143444_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb428b8-39f3-4bd7-82a4-b63f16c1a013",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8388b6-72ea-4bcb-8adc-5e275d001cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, threshold = 0.5):\n",
    "    # convert threshold from probability to logit\n",
    "    threshold_logit = np.log(threshold/(1-threshold))\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    size = len(dataloader.dataset)  # number of samples\n",
    "    stride = dataloader.dataset[0][0].shape[-1]\n",
    "    tot_points = size*stride\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss_sum, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, _, bx, by, bz, ex, ey, ez, jy, _, _, y in dataloader:\n",
    "            pred = model(bx, by, bz, ex, ey, ez, jy)\n",
    "            pred_list.append(pred.cpu().numpy())\n",
    "            test_loss_sum += loss_fn(pred, y).item()  # .item() fetches the python scalar\n",
    "            # number of correct per-point predictions\n",
    "            correct += ((pred > threshold_logit) == y).type(torch.float).sum().item()\n",
    "    tot_pred = np.concatenate(pred_list, axis=0)\n",
    "    test_loss_sum /= num_batches\n",
    "    correct /= tot_points\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.5f}%, Avg loss: {test_loss_sum:>8f} \\n\")    \n",
    "    return tot_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21339b-f8c7-4612-a78b-2c2f489f03cc",
   "metadata": {},
   "source": [
    "### Import the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81dfa017-eb7c-49ce-b5eb-588ee8e30cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' LOAD AND PREPROCESS THE DATA'''\n",
    "basedir = '/tigress/kendrab/21032023/'\n",
    "readpaths = []\n",
    "test_num = 9\n",
    "\n",
    "totdir = basedir+str(test_num)+'/'+'new_better/'\n",
    "for j in range(5,60,5):\n",
    "    readpaths.append(totdir+f\"100samples_idx{j}_bxbybzjyvzexeyez.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d38fec-cac7-4a59-b669-f0daf56e5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = []  # to keep track of which file what sample came from\n",
    "s_list = []\n",
    "bx_list = []\n",
    "by_list = []\n",
    "bz_list = []\n",
    "ex_list = []\n",
    "ey_list = []\n",
    "ez_list = []\n",
    "jy_list = []\n",
    "x0_list = []\n",
    "x1_list = []\n",
    "topo_list = []\n",
    "\n",
    "for idx, filepath in enumerate(readpaths):\n",
    "    with h5py.File(filepath, 'r') as file:\n",
    "        idx_list += [np.array([idx for i in bx]) for bx in file['bx_mms_smooth'][:]]  # check this structure!!!\n",
    "        s_list += list(file['s'][:])\n",
    "        bx_list += list(file['bx_mms_smooth'][:])\n",
    "        by_list += list(file['by_mms'][:])\n",
    "        bz_list += list(file['bz_mms_smooth'][:])\n",
    "        ex_list += list(file['ex_mms'][:]) \n",
    "        ey_list += list(file['ey_mms'][:])\n",
    "        ez_list += list(file['ez_mms'][:])  # vx_mms is simulation vz  thus the filename \n",
    "        jy_list += list(file['jy_mms'][:])\n",
    "        x0_list += list(file['x_mms'][:])\n",
    "        x1_list += list(file['z_mms'][:])\n",
    "        topo_list_tmp = list(file['topo'][:])\n",
    "        for i in range(len(topo_list_tmp)):  # I tried to vectorize this but I didn't get it to work\n",
    "            topo_list_tmp[i] = torch.from_numpy(topo_list_tmp[i].astype(int) % 2)  # cat 0,2 are not plasmoids, cat 1,3 are\n",
    "        topo_list += topo_list_tmp\n",
    "\n",
    "noplasmoids_dir = '/tigress/kendrab/06022023/'\n",
    "noplasmoids_path = noplasmoids_dir+'new_better/'+f\"100samples_idx50_bxbybzjyvzexeyez.hdf5\"  # last file for test dataset\n",
    "\n",
    "with h5py.File(noplasmoids_path, 'r') as file:\n",
    "    idx_list += [np.array([idx for i in bx]) for bx in file['bx_mms_smooth'][:]]  # check this structure!!!\n",
    "    s_list += list(file['s'][:])\n",
    "    bx_list += list(file['bx_mms_smooth'][:])\n",
    "    by_list += list(file['by_mms'][:])\n",
    "    bz_list += list(file['bz_mms_smooth'][:])\n",
    "    ex_list += list(file['ex_mms'][:]) \n",
    "    ey_list += list(file['ey_mms'][:])\n",
    "    ez_list += list(file['ez_mms'][:])\n",
    "    jy_list += list(file['jy_mms'][:])\n",
    "    x0_list += list(file['x_mms'][:])\n",
    "    x1_list += list(file['z_mms'][:])\n",
    "    topo_list_tmp = list(file['topo'][:])\n",
    "    for i in range(len(topo_list_tmp)):  # I tried to vectorize this but I didn't get it to work\n",
    "        topo_list_tmp[i] = torch.from_numpy(topo_list_tmp[i].astype(int) % 2)  # cat 0,2 are not plasmoids, cat 1,3 are\n",
    "    topo_list += topo_list_tmp           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d356c6f-0fc9-4cdb-8f9b-87977f7b495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CHONK UP THE DATA'''\n",
    "# chunk into sliding windows\n",
    "# NOTE TOPO HAS DIFFERENT SEGMENT LENGTHS THAN THE INPUTS (stride vs. 2*padding+stride)\n",
    "idx = batch_unpadded_subsects(idx_list, padding_length, stride)\n",
    "s = batch_subsects(s_list, input_length, stride)  # not going through training so don't need to shape right\n",
    "bx = np.expand_dims(batch_subsects(bx_list, input_length, stride),1)\n",
    "by = np.expand_dims(batch_subsects(by_list, input_length, stride),1)\n",
    "bz = np.expand_dims(batch_subsects(bz_list, input_length, stride),1)\n",
    "ex = np.expand_dims(batch_subsects(ex_list, input_length, stride),1)\n",
    "ey = np.expand_dims(batch_subsects(ey_list, input_length, stride),1)\n",
    "ez = np.expand_dims(batch_subsects(ez_list, input_length, stride),1)\n",
    "jy = np.expand_dims(batch_subsects(jy_list, input_length, stride),1)\n",
    "x0 = batch_unpadded_subsects(x0_list, padding_length, stride)\n",
    "x1 = batch_unpadded_subsects(x1_list, padding_length, stride)\n",
    "topo = batch_unpadded_subsects(topo_list, padding_length, stride)\n",
    "\n",
    "# shuffle the segments so they aren't adjacent to overlapping/similar segments\n",
    "idx, s, bx, by, bz, ex, ey, ez, jy, x0, x1, topo = \\\n",
    "    shuffle(idx, s, bx, by, bz, ex, ey, ez, jy, x0, x1, topo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30de1ec8-570b-4ca9-b4ce-74d7193a1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy arrays to torch tensors (while crying about how many lines of code this is surely there is a better way)\n",
    "idx = torch.from_numpy(idx).to(device, dtype=dtype)\n",
    "s = torch.from_numpy(s).to(device, dtype=dtype)\n",
    "bx = torch.from_numpy(bx).to(device, dtype=dtype)\n",
    "by = torch.from_numpy(by).to(device, dtype=dtype)\n",
    "bz = torch.from_numpy(bz).to(device, dtype=dtype)\n",
    "ex = torch.from_numpy(ex).to(device, dtype=dtype)\n",
    "ey = torch.from_numpy(ey).to(device, dtype=dtype)\n",
    "ez = torch.from_numpy(ez).to(device, dtype=dtype)\n",
    "jy = torch.from_numpy(jy).to(device, dtype=dtype)\n",
    "x0 = torch.from_numpy(x0).to(device, dtype=dtype)\n",
    "x1 = torch.from_numpy(x1).to(device, dtype=dtype)\n",
    "topo = torch.from_numpy(topo).to(device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60604fad-5609-437e-b103-de30eec2462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data into Dataset\n",
    "test_dset = TensorDataset(idx, s, bx, by, bz, ex, ey, ez,\n",
    "                              jy, x0, x1, topo)\n",
    "# Make DataLoaders for the training and test data\n",
    "test_dl = DataLoader(test_dset, batch_size = batch_size)  # batch_size from import_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72705df9-394d-4388-bba4-babf96613a32",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427c7f21-1a87-45ca-bb03-c421eb5cf3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance\n",
      "Test Error: \n",
      " Accuracy: 66.23090%, Avg loss: 0.599586 \n",
      "\n",
      "cat_breakdown\t\t[358877, 114849]\n",
      "torch.Size([100])\n",
      "AUPRC: 0.5629443526268005\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss(reduction='mean')  # We are allowing reduction bc backward() \n",
    "                                            # needs a scalar or to specify a different gradient.\n",
    "                                                # Easier this way. Probably.\n",
    "opt = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "metric = tem.BinaryAUPRC(device=device)\n",
    "\n",
    "print(\"Testing performance\")\n",
    "test_1d_pred = test_loop(test_dl, model, loss_fn).flatten()\n",
    "test_1d = topo.cpu().numpy().flatten() # for confusion matrix \n",
    "num_per_cat = [np.sum(test_1d == i) for i in range(2)]\n",
    "print(f\"cat_breakdown\\t\\t{num_per_cat}\")\n",
    "test_1d_probs = torch.nn.functional.sigmoid(torch.from_numpy(test_1d_pred))  # logit to probability\n",
    "metric.update(test_1d_probs, torch.from_numpy(test_1d))\n",
    "\n",
    "# Plot confusion matrices\n",
    "test_1d_pred_int = test_1d_pred > 0 \n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(6,10))\n",
    "ax[0].set(title=\"Testing Confusion, non-normalized\")\n",
    "ax[1].set(title=\"Testing Confusion, normalized true\")\n",
    "ax[2].set(title=\"Testing Confusion, normalized pred\")\n",
    "cf_test = ConfusionMatrixDisplay(confusion_matrix(test_1d, test_1d_pred_int))\n",
    "cf_test_t = ConfusionMatrixDisplay(confusion_matrix(test_1d, test_1d_pred_int, normalize='true'))\n",
    "cf_test_p = ConfusionMatrixDisplay(confusion_matrix(test_1d, test_1d_pred_int, normalize='pred'))\n",
    "cf_test.plot(ax=ax[0], cmap='Greys', colorbar=False)\n",
    "cf_test_t.plot(ax=ax[1], cmap='Greys', colorbar=False)\n",
    "cf_test_p.plot(ax=ax[2], cmap='Greys', colorbar=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(file_start+\"confusion\"+\".pdf\")\n",
    "plt.close(fig='all')\n",
    "  \n",
    "# plot precision-recall curve for test.\n",
    "test_1d_prob = torch.nn.functional.sigmoid(torch.Tensor(test_1d_pred).to(device))  # to probability rather than logit to see if torcheval really supports logits for this function (it doesn't seem like they do)\n",
    "precision, recall, thresh = tem.functional.binary_binned_precision_recall_curve(test_1d_prob.to(device),\n",
    "                                                                                torch.Tensor(test_1d).to(device), threshold=100)\n",
    "# last point for thresh = 1 is repeated, so we delete it\n",
    "plot_prc(precision[:-1], recall[:-1], thresh, file_start+\"prc_test\", title=\"Precision-Recall curve, test dataset\")\n",
    "print(f\"AUPRC: {metric.compute()}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ea113b8-8afe-4b05-b5f2-3f08dc95cbe3",
   "metadata": {},
   "source": [
    "Validation: negative/positive = 2.26 [652828, 287980]\n",
    "Test: negative/positive = 3.12 [358877, 114849]\n",
    "some performance loss that cannot be explained by data imbalance (see: negative recall 72% vs 63%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667c28d-4a56-45cc-ac52-d2df69912c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find number of completed trials\n",
    "study = optuna.load_study(study_name='model_f_study',storage=\"mysql+mysqldb://optunauser:Frikkenoptuna@stellar-intel.princeton.edu:47793/model_f\",\n",
    "                          pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "comp_trials = 0\n",
    "\n",
    "for trial in study.trials:\n",
    "    if trial.state == 1:  # complete\n",
    "        comp_trials += 1\n",
    "        \n",
    "print(comp_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4127bf-4ae9-4108-8e08-efa674a58225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
