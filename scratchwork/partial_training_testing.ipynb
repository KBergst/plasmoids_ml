{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03412c7-8ab3-4828-a031-0df2f56a0b44",
   "metadata": {},
   "source": [
    "Trying to figure out how backpropagation works when parts of the model are no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95993ac2-724a-4215-9806-bda7afa67938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30458c83-3e19-4232-befa-81177bb47804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatExtract(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()  \n",
    "        self.layers = nn.Sequential(nn.Conv1d(6, 10, 3, padding='same'),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv1d(10, 12, 3, padding='same'),\n",
    "                                    nn.ReLU())\n",
    "    def forward(self, data):\n",
    "        features = self.layers(data)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8937024-17a6-4d6b-a6a2-ec3a6b8a0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()  \n",
    "        self.layers = nn.Sequential(nn.LazyLinear(7),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(7,1),\n",
    "                                   nn.ReLU())\n",
    "    def forward(self, features):\n",
    "        pred = self.layers(features)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a87c47d5-0753-4045-af52-578fe84dccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train(dataloader, feat_extractor, classifier, loss_fn, optimizer_feat, optimizer_cl):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        features = feat_extractor(X)\n",
    "        pred = classifier(features.detach())\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # no minibatching for this example but must do for real model\n",
    "        # train the discriminator\n",
    "        print(\"training discriminator\")\n",
    "        optimizer_cl.zero_grad()\n",
    "        loss = loss_fn(pred,y)\n",
    "        loss.backward()\n",
    "        optimizer_cl.step()\n",
    "        for name, param in classifier.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data)\n",
    "        # Backpropagation- feat extractor\n",
    "        print(\"training feature extractor\")\n",
    "        optimizer_feat.zero_grad()\n",
    "        pred = classifier(features)\n",
    "        reverse_loss = loss_fn(pred, 1-y)  # loss with reversed labels (doesnt make sense with some 'real' data mixed in)\n",
    "        reverse_loss.backward()\n",
    "        optimizer_feat.step() \n",
    "        for name, param in classifier.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data)\n",
    "        \n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a33c0a90-3ffd-4d6f-a936-b879084db36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock data\n",
    "dummy_data_np = rng.random((15,6,1))\n",
    "dummy_cats_np = rng.integers(0, 1, size=(15,1), endpoint=True)\n",
    "dummy_data = torch.from_numpy(dummy_data_np).to(device, dtype=dtype)\n",
    "dummy_cats = torch.from_numpy(dummy_cats_np).to(device, dtype=torch.long)\n",
    "dummy_dset = TensorDataset(dummy_data, dummy_cats)\n",
    "dummy_dl = DataLoader(dummy_dset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d537d1f-efec-475b-a242-50d8a8fc8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "feat = FeatExtract().to(device=device, dtype=torch.double)\n",
    "clas = Classifier().to(device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1de2f17d-6d40-4faa-b781-7026dadf4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizers\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt_feat = torch.optim.Adam(feat.parameters(),lr=0.01)\n",
    "opt_clas = torch.optim.Adam(clas.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dda4268e-05b1-4547-a199-31864d7e0ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9151],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6351],\n",
      "        [ 0.4071],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3641,  0.3440,  0.2790,  0.0856, -0.2187,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9151],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6351],\n",
      "        [ 0.4071],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3641,  0.3440,  0.2790,  0.0856, -0.2187,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "loss: 2.474764  [    1/   15]\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9249],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6251],\n",
      "        [ 0.4169],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3740,  0.3440,  0.2790,  0.0757, -0.2285,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9249],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6251],\n",
      "        [ 0.4169],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3740,  0.3440,  0.2790,  0.0757, -0.2285,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9349],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6151],\n",
      "        [ 0.4269],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3839,  0.3440,  0.2790,  0.0658, -0.2385,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9349],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6151],\n",
      "        [ 0.4269],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3839,  0.3440,  0.2790,  0.0658, -0.2385,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9449],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6051],\n",
      "        [ 0.4369],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3939,  0.3440,  0.2790,  0.0557, -0.2485,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9449],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.6051],\n",
      "        [ 0.4369],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.3939,  0.3440,  0.2790,  0.0557, -0.2485,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9549],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5951],\n",
      "        [ 0.4468],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4040,  0.3440,  0.2790,  0.0457, -0.2585,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9549],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5951],\n",
      "        [ 0.4468],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4040,  0.3440,  0.2790,  0.0457, -0.2585,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9649],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5851],\n",
      "        [ 0.4568],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4140,  0.3440,  0.2790,  0.0356, -0.2685,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9649],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5851],\n",
      "        [ 0.4568],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4140,  0.3440,  0.2790,  0.0356, -0.2685,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9750],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5751],\n",
      "        [ 0.4668],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4241,  0.3440,  0.2790,  0.0255, -0.2786,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9750],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5751],\n",
      "        [ 0.4668],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4241,  0.3440,  0.2790,  0.0255, -0.2786,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9851],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5654],\n",
      "        [ 0.4770],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4343,  0.3440,  0.2790,  0.0152, -0.2888,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9851],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5654],\n",
      "        [ 0.4770],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4343,  0.3440,  0.2790,  0.0152, -0.2888,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-0.9954],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5561],\n",
      "        [ 0.4872],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4446,  0.3440,  0.2790,  0.0049, -0.2990,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-0.9954],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5561],\n",
      "        [ 0.4872],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4316, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4446,  0.3440,  0.2790,  0.0049, -0.2990,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-1.0057],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5476],\n",
      "        [ 0.4975],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4364, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4549,  0.3440,  0.2790, -0.0055, -0.3094,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-1.0057],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5476],\n",
      "        [ 0.4975],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4364, -0.4340, -0.7893,  0.8036,  0.7087, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4549,  0.3440,  0.2790, -0.0055, -0.3094,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3318], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-1.0161],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5403],\n",
      "        [ 0.5079],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4427, -0.4340, -0.7893,  0.7987,  0.7039, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4654,  0.3440,  0.2790, -0.0152, -0.3192,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3366], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-1.0161],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5403],\n",
      "        [ 0.5079],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4427, -0.4340, -0.7893,  0.7987,  0.7039, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4654,  0.3440,  0.2790, -0.0152, -0.3192,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3366], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-1.0266],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5348],\n",
      "        [ 0.5184],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4500, -0.4340, -0.7893,  0.7928,  0.6974, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4759,  0.3440,  0.2790, -0.0242, -0.3285,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3431], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-1.0266],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5348],\n",
      "        [ 0.5184],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4500, -0.4340, -0.7893,  0.7928,  0.6974, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4759,  0.3440,  0.2790, -0.0242, -0.3285,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3431], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-1.0371],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5312],\n",
      "        [ 0.5290],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4583, -0.4340, -0.7893,  0.7857,  0.6898, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4865,  0.3440,  0.2790, -0.0325, -0.3372,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3506], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-1.0371],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5312],\n",
      "        [ 0.5290],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4583, -0.4340, -0.7893,  0.7857,  0.6898, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4865,  0.3440,  0.2790, -0.0325, -0.3372,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3506], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-1.0475],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5290],\n",
      "        [ 0.5394],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4667, -0.4340, -0.7893,  0.7797,  0.6828, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4972,  0.3440,  0.2790, -0.0330, -0.3376,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3577], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-1.0475],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5290],\n",
      "        [ 0.5394],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4667, -0.4340, -0.7893,  0.7797,  0.6828, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.4972,  0.3440,  0.2790, -0.0330, -0.3376,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3577], dtype=torch.float64)\n",
      "training discriminator\n",
      "layers.0.weight tensor([[-1.0580],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5285],\n",
      "        [ 0.5499],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4756, -0.4340, -0.7893,  0.7726,  0.6750, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.5080,  0.3440,  0.2790, -0.0323, -0.3369,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3656], dtype=torch.float64)\n",
      "training feature extractor\n",
      "layers.0.weight tensor([[-1.0580],\n",
      "        [-0.2637],\n",
      "        [ 0.9647],\n",
      "        [ 0.5285],\n",
      "        [ 0.5499],\n",
      "        [-0.8933],\n",
      "        [ 0.6762]], dtype=torch.float64)\n",
      "layers.0.bias tensor([ 0.4756, -0.4340, -0.7893,  0.7726,  0.6750, -0.6917, -0.6832],\n",
      "       dtype=torch.float64)\n",
      "layers.2.weight tensor([[ 0.5080,  0.3440,  0.2790, -0.0323, -0.3369,  0.1508, -0.2734]],\n",
      "       dtype=torch.float64)\n",
      "layers.2.bias tensor([0.3656], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train(dummy_dl, feat, clas, loss_fn, opt_feat, opt_clas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
