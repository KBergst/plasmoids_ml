{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0277be6-f8ab-4e5f-9c45-2a42ce2b147a",
   "metadata": {},
   "source": [
    "### Try to open models you have saved, and then look at them\n",
    "Takeaway: You need to have the model class's code (including all hyperparameters)\n",
    "If you save a Torchscript version using torch.jit.script(model) you do not need to class, but can only use for inference (see saving + loading models pytorch tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6315111-90e3-42b0-a8c1-beffad5179f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b11677-8d07-43ec-b153-342a993ffc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/tigress/kendrab/analysis-notebooks/model_outs/05-07-23/samples/A135332_modelfile.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff2f33a-015f-43f7-812f-513fd02c3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "padding_length = 10  # amount of data on each side of each segment for additional info\n",
    "stride = 10  # size (and therefore spacing) of each segment\n",
    "input_length = stride + 2*padding_length\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "out_channels = 16  # like 'filters' in keras\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b8f696d-8109-4570-9ba5-75a60e002f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO feed hyperparameters into __init__\n",
    "class ModelA(nn.Module):\n",
    "    \"\"\" 1D CNN Model \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # define these all separately because they will get different weights\n",
    "        # consider smooshing these together into one convolution with in_channels=5\n",
    "        self.bx_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool1d(pool_size))\n",
    "        self.by_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool1d(pool_size))\n",
    "        self.bz_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool1d(pool_size))\n",
    "        self.jy_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool1d(pool_size))\n",
    "        self.vz_layers = nn.Sequential(nn.Conv1d(1, out_channels, kernel_size, padding='valid'),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool1d(pool_size))\n",
    "        # TODO split this into CNN and classifier parts to facilitate domain adaptation\n",
    "        self.post_merge_layers = nn.Sequential(nn.Conv1d(out_channels, out_channels*2, kernel_size,\n",
    "                                                         padding='valid'),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.MaxPool1d(pool_size),\n",
    "                                               nn.Flatten(),\n",
    "                                               nn.LazyLinear(stride*2),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Unflatten(1,(2,stride)))\n",
    "                                               \n",
    "\n",
    "    def forward(self, bx, by, bz, jy, vz):\n",
    "        bx_proc = self.bx_layers(bx)\n",
    "        by_proc = self.by_layers(by)\n",
    "        bz_proc = self.bz_layers(bz)\n",
    "        jy_proc = self.jy_layers(jy)\n",
    "        vz_proc = self.vz_layers(vz)\n",
    "        combined = .2*(bx_proc + by_proc + bz_proc + jy_proc + vz_proc)\n",
    "        logits = self.post_merge_layers(combined)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f075b985-62de-4125-bf80-a4be689ed9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelA(\n",
       "  (bx_layers): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (by_layers): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bz_layers): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (jy_layers): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (vz_layers): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (post_merge_layers): Sequential(\n",
       "    (0): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): LazyLinear(in_features=0, out_features=20, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Unflatten(dim=1, unflattened_size=(2, 10))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelA()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "checkpoint = torch.load(model_file)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss_fn = checkpoint['loss_fn']\n",
    "\n",
    "model.eval()  # set to correct mode to get the correct results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c57ecf5f-4310-4989-85a0-94608e9ad987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bx',\n",
       "  'by',\n",
       "  'bz',\n",
       "  'jy',\n",
       "  'vz',\n",
       "  'bx_layers.0',\n",
       "  'bx_layers.1',\n",
       "  'bx_layers.2',\n",
       "  'by_layers.0',\n",
       "  'by_layers.1',\n",
       "  'by_layers.2',\n",
       "  'bz_layers.0',\n",
       "  'bz_layers.1',\n",
       "  'bz_layers.2',\n",
       "  'jy_layers.0',\n",
       "  'jy_layers.1',\n",
       "  'jy_layers.2',\n",
       "  'vz_layers.0',\n",
       "  'vz_layers.1',\n",
       "  'vz_layers.2',\n",
       "  'add',\n",
       "  'add_1',\n",
       "  'add_2',\n",
       "  'add_3',\n",
       "  'mul',\n",
       "  'post_merge_layers.0',\n",
       "  'post_merge_layers.1',\n",
       "  'post_merge_layers.2',\n",
       "  'post_merge_layers.3',\n",
       "  'post_merge_layers.4',\n",
       "  'post_merge_layers.5',\n",
       "  'post_merge_layers.6'],\n",
       " ['bx',\n",
       "  'by',\n",
       "  'bz',\n",
       "  'jy',\n",
       "  'vz',\n",
       "  'bx_layers.0',\n",
       "  'bx_layers.1',\n",
       "  'bx_layers.2',\n",
       "  'by_layers.0',\n",
       "  'by_layers.1',\n",
       "  'by_layers.2',\n",
       "  'bz_layers.0',\n",
       "  'bz_layers.1',\n",
       "  'bz_layers.2',\n",
       "  'jy_layers.0',\n",
       "  'jy_layers.1',\n",
       "  'jy_layers.2',\n",
       "  'vz_layers.0',\n",
       "  'vz_layers.1',\n",
       "  'vz_layers.2',\n",
       "  'add',\n",
       "  'add_1',\n",
       "  'add_2',\n",
       "  'add_3',\n",
       "  'mul',\n",
       "  'post_merge_layers.0',\n",
       "  'post_merge_layers.1',\n",
       "  'post_merge_layers.2',\n",
       "  'post_merge_layers.3',\n",
       "  'post_merge_layers.4',\n",
       "  'post_merge_layers.5',\n",
       "  'post_merge_layers.6'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_graph_node_names(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ef0439-34d1-4253-b32a-0278df0df829",
   "metadata": {},
   "source": [
    "### try to use the feature extractor thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4560dad9-8c86-4ada-9df4-3dde23147c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bx',\n",
       "  'by',\n",
       "  'bz',\n",
       "  'jy',\n",
       "  'vz',\n",
       "  'bx_layers.0',\n",
       "  'bx_layers.1',\n",
       "  'bx_layers.2',\n",
       "  'by_layers.0',\n",
       "  'by_layers.1',\n",
       "  'by_layers.2',\n",
       "  'bz_layers.0',\n",
       "  'bz_layers.1',\n",
       "  'bz_layers.2',\n",
       "  'jy_layers.0',\n",
       "  'jy_layers.1',\n",
       "  'jy_layers.2',\n",
       "  'vz_layers.0',\n",
       "  'vz_layers.1',\n",
       "  'vz_layers.2',\n",
       "  'add',\n",
       "  'add_1',\n",
       "  'add_2',\n",
       "  'add_3',\n",
       "  'mul',\n",
       "  'post_merge_layers.0',\n",
       "  'post_merge_layers.1',\n",
       "  'post_merge_layers.2',\n",
       "  'post_merge_layers.3'],\n",
       " ['bx',\n",
       "  'by',\n",
       "  'bz',\n",
       "  'jy',\n",
       "  'vz',\n",
       "  'bx_layers.0',\n",
       "  'bx_layers.1',\n",
       "  'bx_layers.2',\n",
       "  'by_layers.0',\n",
       "  'by_layers.1',\n",
       "  'by_layers.2',\n",
       "  'bz_layers.0',\n",
       "  'bz_layers.1',\n",
       "  'bz_layers.2',\n",
       "  'jy_layers.0',\n",
       "  'jy_layers.1',\n",
       "  'jy_layers.2',\n",
       "  'vz_layers.0',\n",
       "  'vz_layers.1',\n",
       "  'vz_layers.2',\n",
       "  'add',\n",
       "  'add_1',\n",
       "  'add_2',\n",
       "  'add_3',\n",
       "  'mul',\n",
       "  'post_merge_layers.0',\n",
       "  'post_merge_layers.1',\n",
       "  'post_merge_layers.2',\n",
       "  'post_merge_layers.3'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_feats = create_feature_extractor(model, return_nodes=[\"post_merge_layers.3\",])\n",
    "get_graph_node_names(model_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a8198-288e-4a5d-a11a-b100487c2638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
